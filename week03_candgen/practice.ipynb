{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Recommender Systems YSDA Course</center></h1>\n",
    "<h1><center>Practice №3 Candidate Generation</center></h1>\n",
    "\n",
    "<center><img src=\"https://avatars.mds.yandex.net/get-grocery-goods/2783132/ab847ff6-95e3-4c4e-831a-0576d1949a9e/orig\" width=\"300\" /></center>\n",
    "\n",
    "In this practicte we are going to:\n",
    "- implement some common recommender system components, known as candidate generators, used for fast early stage retrieval.\n",
    "- measure some metrics for them\n",
    "- test them for a user, who really likes fast food!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you are running this notebook in colab, datasphere, etc - you need to clone the repository first\n",
    "\n",
    "# !git clone https://github.com/yandexdataschool/recsys_course\n",
    "# !pip install -e recsys_course/grocery\n",
    "# !pip install implicit==0.7.2 transformers==4.49.0 joblib==1.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import polars as pl\n",
    "import implicit\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "\n",
    "One of the main tasks of candidate generators is to find all the potentially relevant items, so that later stages, such as ranking and reranking, could be a lot more complex and require more features and heavier models. By using them we are effectively reducing the number of scored candidates from whole dictionary of items (for TikTok-like systems it's rather impossible) to hundreds or sometimes even thousands.\n",
    "\n",
    "One of the most popular to evaluate candidate generation is to measure recall or recall@K, and we'll stick by it for this practice and homework. However, evaluating precision or the integral perfomance is also important (see [here](https://t.me/WazowskiRecommends/59), why optimizing recall can be bad).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grocery.recommender.primitives import Candidate\n",
    "from grocery.metrics.base import Metric, Evaluator\n",
    "\n",
    "from grocery.utils.viewer import show_posters, build_item_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll leave the details of the implementation in the imported lib, but the definitions and explanations are below.\n",
    "\n",
    "```python\n",
    "\n",
    "\n",
    "class Metric(ABC):\n",
    "    def __init__(self,\n",
    "                 k: int | None = None,\n",
    "                 reduce_function: str = \"mean\",\n",
    "                 name: str = \"Metric\",\n",
    "                 ):\n",
    "        # filling all the fields here\n",
    "\n",
    "    @abstractmethod\n",
    "    def compute(self,\n",
    "                predictions: list[Candidate],\n",
    "                user_id: int | None = None,\n",
    "                positives: list[int] | None = None\n",
    "                ) -> float:\n",
    "        # implement all the computations here, possible to use other data\n",
    "        # which can be added in the __init__ method\n",
    "\n",
    "\n",
    "class Evaluator:\n",
    "    def __init__(self,\n",
    "                 metrics: list[Metric],\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        Computes the set of metrics for all the data.\n",
    "        Args:\n",
    "            metrics (list[Metric]): metrics to evaluate\n",
    "        \"\"\"\n",
    "    \n",
    "    def load_test_actions(self, actions: pl.Dataframe):\n",
    "        \"\"\"\n",
    "        Load the data from action-format dataframe. The data is expected to have columns:\n",
    "        (request_id, user_id, item_id, timestamp) -> per request aggregation will be used.\n",
    "        Args:\n",
    "            actions (pl.Dataframe): test dataset, used for metric computation\n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "    def evaluate(self, recommend_callable) -> dict[str, float]:\n",
    "        \"\"\"\n",
    "        Runs the evaluation, calling the argument function for each request.\n",
    "        Function should take user_id and max_k and return a list of recommendations.\n",
    "        Examples:\n",
    "            - lambda user_id, n: recommender.recommend(user_id, n)\n",
    "            - lambda user_id, n: candidate_generator.get_candidates(user_id, n)\n",
    "        Args:\n",
    "            recommend_callable (Callable[[int, int], list[Candidate]]): a function to retrieve the ranked items\n",
    "            with signature like `recommend(user_id, num_items) -> list[candidate]`\n",
    "\n",
    "        Returns:\n",
    "            dict[str, float]: dictionary of metric values, aggregated by the metric's reduce function\n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to implement the recall as a metric adapter, so we can use it with evaluator with different models later only by implementing the `get_candidates` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recall(Metric):\n",
    "    def __init__(self, k: int | None = None):\n",
    "        # TODO - add your code here\n",
    "        pass\n",
    "\n",
    "    def compute(self,\n",
    "                predictions: list[Candidate],\n",
    "                positives: list[int],\n",
    "                user_id: int | None = None,\n",
    "                ) -> float:\n",
    "        # TODO - add your code here\n",
    "        # user_id is not used in this metric\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple test\n",
    "\n",
    "predictions = [\n",
    "    Candidate(id=1),\n",
    "    Candidate(id=2),\n",
    "    Candidate(id=3),\n",
    "    Candidate(id=8),\n",
    "    Candidate(id=9),\n",
    "    Candidate(id=3),\n",
    "    Candidate(id=1),\n",
    "]\n",
    "positives = {1, 3, 7, 8, 10, 16}\n",
    "assert np.allclose(float(Recall(k=2).compute(predictions, positives)), 1 / 6)\n",
    "assert np.allclose(float(Recall(k=4).compute(predictions, positives)), 3 / 6)\n",
    "assert np.allclose(float(Recall().compute(predictions, positives)), 3 / 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "Today's practice, as the last one, will be one the Yandex Lavka dataset of e-grocery recommendations.\n",
    "\n",
    "**Pros:**\n",
    "- Items can be recommended multiple times, because users often buy same food, and of the challenges in this type of recsys is to actually find recurring patterns.\n",
    "- Relatively small, if we are going to focus on only cart update actions - for classic retrieval models it's enough. In ranking seminar we are going to use a full-scale version with views as negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data/lavka\"\n",
    "\n",
    "# from grocery.utils.dataset import download_and_extract\n",
    "# download_and_extract(\n",
    "#     url=\"https://www.kaggle.com/api/v1/datasets/download/thekabeton/ysda-recsys-2025-lavka-dataset\",\n",
    "#     filename=\"lavka.zip\",\n",
    "#     dest_dir=DATA_DIR\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data, leave only the cart updates\n",
    "\n",
    "data = (\n",
    "    pl.scan_parquet(f\"{DATA_DIR}/train.parquet\")\n",
    "    .filter(pl.col(\"action_type\") == \"AT_CartUpdate\")\n",
    "    .collect()\n",
    ")\n",
    "\n",
    "item_data = build_item_data(\n",
    "    pl.scan_parquet(\"../data/lavka/train.parquet\")\n",
    ")\n",
    "\n",
    "# leave a subset with only actions and timestamps\n",
    "\n",
    "mlm_format_data = data.select(\n",
    "    pl.col(\"user_id\"),\n",
    "    pl.col(\"product_id\").alias(\"item_id\"),\n",
    "    pl.col(\"request_id\"),\n",
    "    pl.lit(1).alias(\"rating\"),\n",
    "    pl.col(\"timestamp\"),\n",
    "    pl.col(\"product_category\"),\n",
    "    pl.col(\"product_name\"),\n",
    ")\n",
    "\n",
    "# global timepoint split!\n",
    "\n",
    "train, test = train_test_split(mlm_format_data.sort(\"timestamp\"), test_size=0.2, shuffle=False)\n",
    "assert train[\"timestamp\"].max() <= test[\"timestamp\"].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also add a fake user, who loves Lipton, Coca-Cola and junk food, plus a helper function to print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_user = 1\n",
    "sample_items = [\n",
    "    11586455112286391814,\n",
    "    8817037096041388006,\n",
    "    11900971701009971240,\n",
    "    8503917216033445244,\n",
    "    7316856031090433857,\n",
    "    8710220968864885647,\n",
    "    1374883856065269554,\n",
    "    1810251580582886524,\n",
    "    4717741123299363694,\n",
    "    17855866158081617024,\n",
    "]\n",
    "\n",
    "mock_user_actions = pl.DataFrame({\n",
    "    \"user_id\": [sample_user] * len(sample_items),\n",
    "    \"item_id\": sample_items,\n",
    "    \"request_id\": np.arange(1, len(sample_items) + 1) * random.randint(63, 76),\n",
    "    \"rating\": [1] * len(sample_items),\n",
    "    \"timestamp\": [train[\"timestamp\"].max() - 3600] * len(sample_items),\n",
    "}).select(\n",
    "    pl.col(\"user_id\").cast(pl.UInt64),\n",
    "    pl.col(\"item_id\").cast(pl.UInt64),\n",
    "    pl.col(\"request_id\").cast(pl.UInt64),\n",
    "    pl.col(\"rating\").cast(pl.Int32),\n",
    "    pl.col(\"timestamp\"),\n",
    ")\n",
    "\n",
    "mock_user_actions = mock_user_actions.join(\n",
    "    (\n",
    "        pl.scan_parquet(\"../data/lavka/train.parquet\")\n",
    "        .select(\n",
    "            pl.col(\"product_id\").alias(\"item_id\"),\n",
    "            pl.col(\"product_category\"),\n",
    "            pl.col(\"product_name\"),\n",
    "        )\n",
    "        .unique()\n",
    "        .collect()\n",
    "    ),\n",
    "    on=\"item_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "train = pl.concat([train, mock_user_actions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_posters(sample_items, item_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this will be our final evaluator with metrics set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grocery.metrics.quality import NDCG\n",
    "from grocery.metrics.aspects import CategoryDiversity, Novelty\n",
    "\n",
    "evaluator = Evaluator(\n",
    "    metrics=[\n",
    "        Recall(10),\n",
    "        Recall(100),\n",
    "        NDCG(100),\n",
    "        Novelty(train, 10),\n",
    "        Novelty(train, 100),\n",
    "        CategoryDiversity(train, 10),\n",
    "        CategoryDiversity(train, 100),\n",
    "    ]\n",
    ")\n",
    "\n",
    "evaluator.load_test_actions(\n",
    "    test.filter(pl.col(\"user_id\").is_in(train[\"user_id\"].unique()))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Candidate generators 101\n",
    "Now let's talk business - candidate generators. We want a class with following interface:\n",
    "\n",
    "```python\n",
    "class CandidateGenerator:\n",
    "    @abstractmethod\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the candidate generator.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def extract_candidates(self, object_id: int, n: int = 10) -> list[Candidate]:\n",
    "        \"\"\"\n",
    "        Extract n candidates for the given id (user or item).\n",
    "        \"\"\"\n",
    "        pass\n",
    "```\n",
    "\n",
    "During the practice, we'll implement and use two of them:\n",
    "- `TopPop` - simply returns most popular items, just aggregates user history.\n",
    "- `KNN` (K nearest neighbors) - extracts the embedding of the object and uses KNN to find objects with high similarity (e.g. dot product).\n",
    "\n",
    "For second we also need some sort of embeddings for users and items, so we are going to implement two collaborative feedback models and one way to use pretrained language models for content-based generation.\n",
    "\n",
    "For now, let's deal with the TopPop and measure the metrics - it will be some sort of baseline solution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grocery.recommender import CandidateGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopPop(CandidateGenerator):\n",
    "    def __init__(self,\n",
    "                 interactions: pl.DataFrame,\n",
    "                 ):\n",
    "        # TODO - add your code here\n",
    "        pass\n",
    "\n",
    "    def extract_candidates(self, object_id: int, n: int = 10) -> list[Candidate]:\n",
    "        # TODO - add your code here\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg = TopPop(train)\n",
    "\n",
    "metrics = evaluator.evaluate(lambda user_id, n: cg.extract_candidates(user_id, n))\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = cg.extract_candidates(sample_user, 10)\n",
    "show_posters([c.id for c in candidates], item_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN Candidate Generator\n",
    "Let's write a lightweight, but actually usable candidate generator! It will be a kNN search, where distance metric is dot-product and closer to 1 is better. This is essentially really useful when you train models to predict score with dot-product of two embedding, just as our ALS model.\n",
    "\n",
    "A small description:\n",
    "- Initialization requires `left_embeddings` (user or item ones) and `right_embeddings` (item ones).\n",
    "- Embeddings are a dictionary with item ids as keys and np.array of fixed dimension as values.\n",
    "- The same dictionary can be passed as both arguments, if you want to use it for the item-to-item recommendations.\n",
    "- `extract_candidates` gets the object_id, gets the embedding for it, calculates distances to all other embeddings, sorts them and returns the top n candidates - not really efficient, but it will be the exact closest items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotProductKNN(CandidateGenerator):\n",
    "    def __init__(self,\n",
    "                 left_embeddings: dict[int, np.array],\n",
    "                 right_embeddings: dict[int, np.array],\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        # TODO - add your code here\n",
    "        pass\n",
    "\n",
    "\n",
    "    def extract_candidates(\n",
    "        self,\n",
    "        object_id: int,\n",
    "        n: int = 10,\n",
    "        ) -> list[Candidate]:\n",
    "        # TODO - add your code here\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, now we actually need some embeddings!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content-only candidate generation\n",
    "\n",
    "Sometimes we may want to find items relevant not for a specific user in general, but rather relevant given the context of the current item the user is looking at - similar videos on YouTube, similar clothing in Wildberries, complements or substitutes for a given product (no microeconomics here, I promise).\n",
    "\n",
    "What if we do not want to train anything and definitely do not want spend a lot of compute on a regular basis to recalculate the item factors? There is an easy way - you can use content data. Let's try using text from title or a picture of products to find similar products to a certain food item, not using the feedback data. Our first step will be to get a fancy NLP model from somewhere and extract some embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "model_id = \"DeepPavlov/rubert-base-cased\"\n",
    "pipe = pipeline('feature-extraction', model=model_id)\n",
    "\n",
    "text_embeddings = {}\n",
    "if os.path.exists(\"text_embeddings.pkl\"):\n",
    "    text_embeddings = joblib.load(\"text_embeddings.pkl\")\n",
    "else:\n",
    "    products = train.select(\"product_name\", \"item_id\").unique()\n",
    "    for text, iid in tqdm(products.iter_rows(), total=len(products)):\n",
    "        text_embeddings[iid] = np.array(pipe(text))[0, 0]\n",
    "    joblib.dump(text_embeddings, \"text_embeddings.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But how do we actually get user embeddings for quierying? There are a lot of approaches:\n",
    "- Gather all the user history, calculate distances from each candidate to every item in history and reduce it (mean / max).\n",
    "- Calculate some sort of averaged user embedding ahead of time, for example exponentially smoothed mean - the last items have more weight, than the previous ones.\n",
    "\n",
    "We are going to try out the latter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mean_embeddings = {}\n",
    "\n",
    "for user_id, items in (\n",
    "    train\n",
    "    .select(\"user_id\", \"item_id\", \"timestamp\")\n",
    "    .group_by(\"user_id\")\n",
    "    .agg(pl.struct(\"item_id\", \"timestamp\").alias(\"items\"))\n",
    ").iter_rows():\n",
    "    items = sorted(items, key=lambda x: x[\"timestamp\"])\n",
    "    user_embed = np.zeros(768)\n",
    "    alpha = 0.7\n",
    "    for item in items:\n",
    "        user_embed = (1 - alpha) * user_embed + alpha * text_embeddings[item[\"item_id\"]]\n",
    "    user_mean_embeddings[user_id] = user_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg = DotProductKNN(user_mean_embeddings, text_embeddings)\n",
    "\n",
    "metrics = evaluator.evaluate(lambda user_ids, n: cg.batch_extract_candidates(user_ids, n), batch_size=128)\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = cg.extract_candidates(sample_user, 10)\n",
    "show_posters([c.id for c in candidates], item_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems to be working and actually is not a bad way to add diversity to your candidates or encourage item exploration, because this candidate is not affected by feedback loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Factorization\n",
    "\n",
    "Now to some more robust things, actually used in production - simple and powerful. As you were told in the lecture, matrix factorization is a powerful technique for collaborative filtering.\n",
    "There are several popular methods, for example:\n",
    "- Using alternating least squares or ALS.\n",
    "- Using alternating optimization of log-likelihood instead of MSE.\n",
    "- Using stochastic optimization of MSE (SVD++ and variations).\n",
    "- Using Bayesian Personalized Ranking with custom loss function.\n",
    "\n",
    "Let's start with building a sparse matrix of user and item interactions, and dictionaries to map `id` of object to it's index in the matrix.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_matrix_with_mappings(ratings: pl.DataFrame, additive: bool = False):\n",
    "    users = ratings.select(pl.col(\"user_id\").unique())\n",
    "    items = ratings.select(pl.col(\"item_id\").unique())\n",
    "    num_users = len(users)\n",
    "    num_items = len(items)\n",
    "    user_id2idx = {row[\"user_id\"]: i for i, row in enumerate(users.iter_rows(named=True))}\n",
    "    item_id2idx = {row[\"item_id\"]: i for i, row in enumerate(items.iter_rows(named=True))}\n",
    "    user_idx2id = {v: k for k, v in user_id2idx.items()}\n",
    "    item_idx2id = {v: k for k, v in item_id2idx.items()}\n",
    "    R = sp.sparse.lil_array((num_users, num_items))\n",
    "    for row in ratings.iter_rows(named=True):\n",
    "        user_idx = user_id2idx[row[\"user_id\"]]\n",
    "        item_idx = item_id2idx[row[\"item_id\"]]\n",
    "        if additive:\n",
    "            R[user_idx, item_idx] += row[\"rating\"]\n",
    "        else:\n",
    "            R[user_idx, item_idx] = row[\"rating\"]\n",
    "    R = R.tocsr()\n",
    "    return R, (user_id2idx, item_id2idx, user_idx2id, item_idx2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternating Least Squares\n",
    "\n",
    "\n",
    "The idea is that we predict the score with the following formula: $\\hat{r}_{ui} = \\langle p_u, q_u \\rangle + b_{u} + b_{i}$, where $p_u \\in \\mathbb{R}^d$ и $q_i \\in \\mathbb{R}^d$ are latent vectors for user $u$ and item $i$ and $b$ are biases.\n",
    "\n",
    "We will be optimizing MSE between true values and predictions, but with regularization:\n",
    "$$\n",
    "L = \\sum_{(u, i) \\in R} (\\hat{r}_{ui} - r_{ui} - b_{u} - b_{i})^2 + \\lambda_{emb} \\left(\\sum_{u \\in U} \\|p_u\\|^2 + \\sum_{i \\in I} \\|q_i\\|^2\\right) + \\lambda_{bias} \\left(\\sum_{u \\in U} b_u^2 + \\sum_{i \\in I} b_i^2\\right)\n",
    "$$\n",
    "\n",
    "Assuming you've heard about the model during lecture on candidate generation, we're now going to:\n",
    "1. Derive the parameter update formulas\n",
    "2. Code them and implement the model's `fit` method!\n",
    "\n",
    "#### Step formula for ALS\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary> Derivation of the formulas </summary>\n",
    "\n",
    "User embeddings: \n",
    "\n",
    "$$\\nabla_{p_u}(L) = \\sum_{i \\in I} 2q_i(\\langle p_u, q_i \\rangle + b_u + b_i - r_{ui}) + 2\\lambda_{emb} p_u$$\n",
    "\n",
    "$$\\sum_{i \\in I} 2(\\langle p_u, q_i \\rangle + b_u + b_i - r_{ui})q_i + 2\\lambda_{emb} p_u = 0$$\n",
    "\n",
    "$$\\sum_{i \\in I} p_u q_i^T q_i - \\sum_{i \\in I} (r_{ui} - b_u - b_i)q_i + \\lambda_{emb} p_u = 0$$\n",
    "\n",
    "$$p_u \\left(\\sum_{i \\in I} q_i^T q_i + \\lambda_{emb} I \\right) - \\sum_{i \\in I} (r_{ui} - b_u - b_i) q_i = 0$$\n",
    "\n",
    "$$p_u = \\sum_{i \\in I} (r_{ui} - b_u - b_i) q_i \\left(\\sum_{i \\in I} q_i^T q_i + \\lambda_{emb} I \\right)^{-1}$$\n",
    "\n",
    "User biases:\n",
    "\n",
    "$$\\nabla_{b_u}(L) = \\sum_{i \\in I} 2(\\langle p_u, q_i \\rangle + b_u + b_i - r_{ui}) + 2\\lambda_{bias} b_u$$\n",
    "\n",
    "$$\\sum_{i \\in I} (\\langle p_u, q_i \\rangle + b_u + b_i - r_{ui}) + \\lambda_{bias} b_u = 0$$\n",
    "\n",
    "$$\\sum_{i \\in I} b_u + \\lambda_{bias} b_u = \\sum_{i \\in I} (r_{ui} - \\langle p_u, q_i \\rangle - b_i) $$\n",
    "\n",
    "$$ b_u = \\frac{1}{ \\|I\\| + \\lambda_{bias} }\\sum_{i \\in I}(r_{ui} - \\langle p_u, q_i \\rangle - b_i) $$\n",
    "\n",
    "The same can be done for item parameters.\n",
    "\n",
    "</details>\n",
    "\n",
    "$$ P = (R - B_u - B_i)Q \\left(Q^TQ + \\lambda_{emb} I \\right)^{-1} $$\n",
    "\n",
    "$$ B_u = \\frac{1}{ \\|I\\| + \\lambda_{bias} }(R - PQ^T - B_i) $$\n",
    "\n",
    "$$ Q = (R - B_u - B_i)^T P \\left(P^TP + \\lambda_{emb} I \\right)^{-1} $$\n",
    "\n",
    "$$ B_i = \\frac{1}{ \\|U\\| + \\lambda_{bias} }(R - PQ^T - B_u) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorization(ABC):\n",
    "    def __init__(self, dim: int, max_iter: int, lr: float, reg_embeddings: float, reg_biases: float):\n",
    "        self.lr = lr\n",
    "        self.dim = dim\n",
    "        self.max_iter = max_iter\n",
    "        self.reg_embeddings = reg_embeddings\n",
    "        self.reg_biases = reg_biases\n",
    "\n",
    "    def _init_parameters(self, ratings: pl.DataFrame, additive_feedback=False):\n",
    "        self.R, (\n",
    "            self.user_id2idx,\n",
    "            self.item_id2idx,\n",
    "            self.user_idx2id,\n",
    "            self.item_idx2id\n",
    "        ) = build_matrix_with_mappings(ratings, additive=additive_feedback)\n",
    "        self.n_users, self.n_items = self.R.shape\n",
    "        self.user_vectors = np.random.normal(size=(self.n_users, self.dim))\n",
    "        self.item_vectors = np.random.normal(size=(self.n_items, self.dim))\n",
    "        self.user_biases = np.zeros((self.n_users, 1))\n",
    "        self.item_biases = np.zeros((self.n_items, 1))\n",
    "\n",
    "    @abstractmethod\n",
    "    def fit(self, ratings: pl.DataFrame):\n",
    "        pass\n",
    "\n",
    "    def extract_model_to_dicts(self):\n",
    "        left_biases, left_embeddings = {}, {}\n",
    "        for user_id, user_idx in self.user_id2idx.items():\n",
    "            left_embeddings[user_id] = self.user_vectors[user_idx]\n",
    "            left_biases[user_id] = self.user_biases[user_idx]\n",
    "        right_biases, right_embeddings = {}, {}\n",
    "        for item_id, item_idx in self.item_id2idx.items():\n",
    "            right_embeddings[item_id] = self.item_vectors[item_idx]\n",
    "            right_biases[item_id] = self.item_biases[item_idx]\n",
    "        return {\n",
    "            \"left_embeddings\": left_embeddings,\n",
    "            \"right_embeddings\": right_embeddings,\n",
    "            \"left_biases\": left_biases,\n",
    "            \"right_biases\": right_biases,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ALS(MatrixFactorization):\n",
    "    def __init__(self, \n",
    "                 dim: int,\n",
    "                 max_iter: int,\n",
    "                 lr: float,\n",
    "                 reg_embeddings: float,\n",
    "                 reg_biases: float\n",
    "                 ):\n",
    "        super().__init__(dim, max_iter, lr, reg_embeddings, reg_biases)\n",
    "\n",
    "\n",
    "    def fit(self, ratings: pl.DataFrame):\n",
    "        # TODO - your code here\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "als = ALS(max_iter=50)\n",
    "als.fit(train)\n",
    "\n",
    "embeds = als.extract_model_to_dicts()\n",
    "cg = DotProductKNN(embeds[\"left_embeddings\"], embeds[\"right_embeddings\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = evaluator.evaluate(lambda user_ids, n: cg.batch_extract_candidates(user_ids, n), batch_size=128)\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = cg.extract_candidates(sample_user, 10)\n",
    "show_posters([c.id for c in candidates], item_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an interesting property with iALS models: the norm of vectors correlates with item popularity or user popularity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_popularity = train.group_by(\"item_id\").agg(pl.col(\"rating\").count().alias(\"popularity\"))\n",
    "item_popularity = item_popularity.with_columns(\n",
    "    norms=np.array([np.linalg.norm(embeds[\"right_embeddings\"][iid]) for iid in item_popularity[\"item_id\"]])\n",
    ")\n",
    "\n",
    "print(item_popularity[\"popularity\", \"norms\"].corr())\n",
    "\n",
    "user_hotnesss = train.group_by(\"user_id\").agg(pl.col(\"rating\").count().alias(\"hotness\"))\n",
    "user_hotnesss = user_hotnesss.with_columns(\n",
    "    norms = np.array([np.linalg.norm(embeds[\"left_embeddings\"][uid]) for uid in user_hotnesss[\"user_id\"]])\n",
    ")\n",
    "\n",
    "print(user_hotnesss[\"hotness\", \"norms\"].corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Matrix Factorization\n",
    "\n",
    "We model the probability of the interaction as follows:\n",
    "\n",
    "$$P(r_{ui} = 1 | p_u, q_i, b_u, b_i) = \\sigma \\left( \\langle p_u, q_u \\rangle + b_{u} + b_{i} \\right)$$\n",
    "\n",
    "Where $\\sigma(x)$ is a sigmoid function, and other parameters are the same as in ALS.\n",
    "\n",
    "$$\\sigma(x) = \\frac{1}{1 + \\exp(-x)}$$\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary> Derivation of the formulas </summary>\n",
    "\n",
    "Let also $x_{ui}$ be a logit of the model:\n",
    "\n",
    "$$x_{ui} = \\langle p_u, q_u \\rangle + b_{u} + b_{i}$$\n",
    "$$\\nabla_{p_{u}}(x_{ui}) = q_i$$\n",
    "$$\\nabla_{q_{i}}(x_{ui}) = p_u$$\n",
    "$$\\nabla_{b_{u}}(x_{ui}) = 1$$\n",
    "$$\\nabla_{b_{i}}(x_{ui}) = 1$$\n",
    "\n",
    "For a binary observation, likelihood is modeled like this:\n",
    "\n",
    "$$p(r_{ui} | p_u, q_i, b_u, b_i) =  \\sigma ( x_{ui} )^{r_{ui}} \\left( 1 - \\sigma (x_{ui}) \\right)^{1 - r_{ui}}$$\n",
    "\n",
    "$$ l_{ui} = r_{ui} \\log \\left( \\sigma (x_{ui})\\right) + (1 - r_{ui}) \\log \\left( 1 - \\sigma (x_{ui}) \\right)$$\n",
    "\n",
    "The loss will be the log-likelihood with subtracted regularization:\n",
    "$$\n",
    "L = \\sum_{(u, i) \\in R} \\left[ r_{ui} \\log \\left( \\sigma (x_{ui})\\right) + (1 - r_{ui}) \\log \\left( 1 - \\sigma (x_{ui}) \\right) \\right] - \\lambda_{emb} \\left(\\sum_{u \\in U} \\|p_u\\|^2 + \\sum_{i \\in I} \\|q_i\\|^2\\right) - \\lambda_{bias} \\left(\\sum_{u \\in U} b_u^2 + \\sum_{i \\in I} b_i^2\\right)\n",
    "$$\n",
    "\n",
    "It's possible to solve this alternating the gradient **ascent** (or descent, if negative log-likelihood is used with added regularization terms) steps between users and items, freezing the other parameters when making a step. As $\\sigma$ is a logistic function, we can easily derive the derivative by the argument:\n",
    "\n",
    "$$\\nabla_{x_{ui}}(l_{ui}) = r_{ui} - \\sigma (x_{ui})$$\n",
    "$$\\nabla_{p_{u}}(L) = \\sum_{i \\in I} \\left(r_{ui} - \\sigma (x_{ui}) \\right) q_i - \\lambda_{emb} p_u $$\n",
    "$$\\nabla_{b_{u}}(L) = \\sum_{i \\in I} \\left(r_{ui} - \\sigma (x_{ui}) \\right) - \\lambda_{bias} b_u $$\n",
    "\n",
    "The derivation of item gradients is the same.\n",
    "\n",
    "</details>\n",
    "\n",
    "$$p_{u} := p_{u} + \\eta \\left[ \\sum_{i \\in I} \\left(r_{ui} - \\sigma (x_{ui}) \\right) q_i - \\lambda_{emb} p_u \\right]$$\n",
    "$$b_{u} := b_{u} + \\eta \\left[ \\sum_{i \\in I} \\left(r_{ui} - \\sigma (x_{ui}) \\right) - \\lambda_{bias} b_u \\right]$$\n",
    "$$q_{i} := q_{i} + \\eta \\left[ \\sum_{i \\in I} \\left(r_{ui} - \\sigma (x_{ui}) \\right) p_u - \\lambda_{emb} q_i \\right]$$\n",
    "$$b_{i} := b_{i} + \\eta \\left[ \\sum_{i \\in I} \\left(r_{ui} - \\sigma (x_{ui}) \\right) - \\lambda_{bias} b_i \\right]$$\n",
    "\n",
    "Next - implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticMF(MatrixFactorization):\n",
    "    def __init__(self,\n",
    "                 dim: int = 128,\n",
    "                 max_iter: int = 300,\n",
    "                 lr: float = 0.003,\n",
    "                 reg_embeddings: float = 0.01,\n",
    "                 reg_biases: float = 0.01,\n",
    "                 ):\n",
    "        # TODO - your code here\n",
    "        pass\n",
    "\n",
    "    def fit(self, ratings: pl.DataFrame, additive_feedback=False):\n",
    "        # TODO - your code here\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmf = LogisticMF(max_iter=50)\n",
    "lmf.fit(train)\n",
    "\n",
    "embeds = lmf.extract_model_to_dicts()\n",
    "cg = DotProductKNN(embeds[\"left_embeddings\"], embeds[\"right_embeddings\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = evaluator.evaluate(lambda user_ids, n: cg.batch_extract_candidates(user_ids, n), batch_size=128)\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = cg.extract_candidates(sample_user, 10)\n",
    "show_posters([c.id for c in candidates], item_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In homework, your assingment will be to implement the other mentioned algorithm - BPR. You will also implement two other somewhat similar approaches - EASE and SLIM, which build an item-to-item similarity matrix and find items, similar to user history.\n",
    "\n",
    "Save this notebook, cause you'll need the metrics and the models for comparison!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing with some benchmarks\n",
    "Let's compare the quality of our solution with the `implicit` library - a popular way to do matrix factorization.\n",
    "\n",
    "In terms of speed, GPU support and scaling `implicit` is 100% better, but we should not fall back on quality too much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "additive = True\n",
    "\n",
    "R, (user_id2idx, item_id2idx, user_idx2id, item_idx2id) = build_matrix_with_mappings(train, additive=additive)\n",
    "model = implicit.als.AlternatingLeastSquares(factors=128, iterations=100)\n",
    "model.fit(R)\n",
    "\n",
    "left_embeddings = {}\n",
    "for user_id, user_idx in user_id2idx.items():\n",
    "    left_embeddings[user_id] = model.user_factors[user_idx]\n",
    "right_embeddings = {}\n",
    "for item_id, item_idx in item_id2idx.items():\n",
    "    right_embeddings[item_id] = model.item_factors[item_idx]\n",
    "\n",
    "cg = DotProductKNN(left_embeddings, right_embeddings)\n",
    "metrics = evaluator.evaluate(lambda user_ids, n: cg.batch_extract_candidates(user_ids, n), batch_size=128)\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = cg.extract_candidates(sample_user, 10)\n",
    "show_posters([c.id for c in candidates], item_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
