{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "727c94ad",
   "metadata": {},
   "source": [
    "# Домашняя работа №2: Нейросетевое ранжирование и анализ историй трансформером\n",
    "\n",
    "На семинарах были рассмотрены различные методы и идеи ручного составления признаков для задачи ранжирования. В этом семинаре мы посмотрим, как этот процесс можно автоматизировать с помощью применения трансформера над историей взаимодействий пользователя. Строить алгоритм будем на данных из вашего контеста."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb271239",
   "metadata": {},
   "source": [
    "## 1. Общая схема алгоритма\n",
    "\n",
    "Алгоритм, который вы будете реализовывать, будет представлять собой применение трансформера к истории позитивных взаимодействий пользователя. В нашем случае это клики, корзины и покупки. Просмотры учитывать можно и нужно, но для упрощения задачи будем их игнорировать.\n",
    "\n",
    "Обучение модели будет состоять из двух частей: pretrain и finetune. Pretrain представляет из себя обучение на некоторую общую задачу, которая максимально утилизирует все имеющиеся данные. Такие задачи, как правило, хорошо \"масштабируются\", то есть добавление данных и увеличение модели приводит к повышению качества. Finetune представляет из себя выравнивание модели с целевой задачей. Это, как правило, более разреженная задача. В нашем случае целевой метрикой является ndcg@10 по группам (request_id) на тесте. Для этого хорошо работает обучение на попарную функцию потерь в рамках этих групп. Мы будем использовать [Calibrated Pairwise Logistic](https://arxiv.org/pdf/2211.01494) (см. далее). Метки в группе будут 0 для просмотра и 1 для корзины. Клики и покупки не учитываются, т.к. их нет в итоговом тесте. Задача - отранжировать единички (корзины) как можно выше ноликов (просмотров).\n",
    "\n",
    "Далее будет краткое описание каждой из задач, конкретные особенности в следующих разделах."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8affb83",
   "metadata": {},
   "source": [
    "### Pretrain:\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"https://i.ibb.co/8GksnWD/Screenshot-2025-05-04-at-10-15-36.png\" width=\"500\" alt=\"pretrain\">\n",
    "</div>\n",
    "\n",
    "Pretrain будет состоять из двух задач: next-positive prediction и feedback prediction.\n",
    "\n",
    "#### Next-positive prediction\n",
    "\n",
    "Концептуально задача заключаетя в предсказании следующего положительного взаимодействия пользователя на основе истории всех предыдущих положительных взаимодействий. У каждого положительного взаимодействия есть три характеристики:\n",
    "- Товар, с которым было сделано взаимодействие\n",
    "- Контекст, в котором было сделано взаимодействие (поверхность, время и т.п.)\n",
    "- Фидбек этого взаимодействия (например, клик).\n",
    "\n",
    "Каждую характеристику можно закодировать в виде вектора (про это далее). Модель получает историю в виде последовательности токенов, каждый из которых представляется в виде суммы $c_t, i_t, f_t$, где\n",
    "\n",
    "- $c_t$ – контекст t-го взаимодействия,  \n",
    "- $i_t$ – товар взаимодействия,  \n",
    "- $f_t$ – наблюдаемый фидбэк (клик, корзина, покупка).\n",
    "\n",
    "Задача:\n",
    "$$\n",
    "P(\\text{item}=i_t\\mid \\text{history}=S_{t-1},\\;\\text{context}=c_t)\\,.\n",
    "$$\n",
    "\n",
    "Используем softmax по множеству всех товаров для моделирования такой вероятности. Близость между товаром и парой (контекст, пользователь) считаем через косинус. Обучаться будем на кросс-энтропию.\n",
    "\n",
    "#### Feedback prediction\n",
    "\n",
    "Задача:\n",
    "$$\n",
    "P(\\text{feedback}=f_t\\mid \\text{history}=S_{t-1},\\;\\text{context}=c_t,\\;\\text{item}=i_t).\n",
    "$$\n",
    "\n",
    "В нашем случае решаем задачу классификации на три класса: клик, корзина, покупка.\n",
    "\n",
    "Итоговый pretrain лосс:\n",
    "$$\n",
    "\\mathcal{L}_{\\rm pre\\text{-}train}\n",
    "= \\mathcal{L}_{\\mathrm{NPP}} + \\mathcal{L}_{\\mathrm{FP}}.\n",
    "$$\n",
    "\n",
    "#### Позднее связывание\n",
    "\n",
    "- Трансформер выдаёт по одному скрытому состоянию $h_t$ на каждое взаимодействие.  \n",
    "- Для next-positive prediction конкатенируем вектор текущего скрытого состояния $h_{t-1}$ и следующего контекста $c_t$:\n",
    "$$\n",
    "\\hat h^c_t = \\mathrm{MLP}\\bigl(\\mathrm{Concat}(h_{t-1},c_t)\\bigr).\n",
    "$$\n",
    "- Для feedback prediction дополнительно еще конкатенируем вектор следующего товара $i_t$ для предсказания следующего feedback-а:\n",
    "$$\n",
    "\\hat h^i_t = \\mathrm{MLP}\\bigl(\\mathrm{Concat}(h_{t-1},c_t,i_t)\\bigr).\n",
    "$$\n",
    "- Позднее, потому что после применения трансформера."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67330ec3",
   "metadata": {},
   "source": [
    "### Finetune\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://i.ibb.co/kgwt7pRb/Screenshot-2025-05-04-at-10-15-48.png\" width=\"500\" alt=\"finetune\">\n",
    "</p>\n",
    "\n",
    "#### Постановка задачи  \n",
    "Пусть есть пользователь с идентификатором `user_id`. У него сформирована история взаимодействий и набор групп (каждая группа имеет свой `request_id`).  \n",
    "- Скрытые состояния модели на момент каждого взаимодействия:  \n",
    "  $$h_0, h_1, \\dots, h_t$$  \n",
    "- Historical impressions - это последовательность групп, в которых пользователь видел товары.  \n",
    "\n",
    "Каждая группа представляет собой множество товаров c бинарными метками (таргеты) 0 или 1.  \n",
    "Задача finetune - для каждого товара внутри группы оценить его релевантность пользователю, используя состояние пользователя, актуальное на момент показа этой группы.\n",
    "\n",
    "#### Учет задержки (consistency with validation)  \n",
    "На тесте между последним известным состоянием истории и новой группой может пройти от 2 дней до 1 месяца.  \n",
    "Чтобы обучение было консистентно с валидацией, имитируем такой промежуток:\n",
    "\n",
    "1. Случайно выбираем задержку для каждой группы\n",
    "   $$\\Delta \\sim \\mathrm{Uniform}(2\\ \\text{дн.},\\ 32 \\text{дн.}).$$\n",
    "2. Находим первое состояние $h_k$, предшествующее текущей группе не менее чем на $\\Delta$.  \n",
    "3. Используем это состояние $h_k$ как вектор пользователя для расчёта потерь.\n",
    "\n",
    "#### Попарная ранжирующая функция потерь  \n",
    "В рамках каждой группы (`request_id`) формируем все возможные пары товаров $(i,j)$, где товар $i$ имеет таргет 1, а товар $j$ - таргет 0.  \n",
    "Для каждой пары рассчитываем ранжирующую функцию потерь на основе предсказанных релевантностей."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690d22b4",
   "metadata": {},
   "source": [
    "## 2. Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60653f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from collections import deque\n",
    "from typing import Dict, Any, Generator, Iterable, Optional\n",
    "from abc import ABC, abstractmethod\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614d9df1",
   "metadata": {},
   "source": [
    "Скачайте актуальные данные с https://www.kaggle.com/competitions/ysda-recsys-2025-lavka/data.  Оставляем только небольшой поднабор всех признаков. Учесть все имеющиеся признаки можно будет в бонусной части."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f704462",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pl.read_parquet('./data/train.parquet').select(['action_type', 'product_id', 'source_type', 'timestamp', 'user_id', 'request_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8987a472",
   "metadata": {},
   "source": [
    "### Разделение на трейн и валидация (повторяем распределение теста):\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"https://i.ibb.co/yBPn87t7/IMG000-19.jpg\" width=\"500\" alt=\"split\">\n",
    "</div>\n",
    "\n",
    "Для оценки модели будем использовать train данные. Из них сформируем валидационную и обучающую части. Для того, чтобы получить корректные метрики на валидации, важно повторить все особенности тестовых данных:\n",
    "- 2 дня разница между train и valid\n",
    "- 1 месяц на valid\n",
    "- оставляем только просмотр и корзину\n",
    "- группы с >= 10 товарами\n",
    "- группы с хотя бы одной корзиной и хотя бы одним просмотром"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde01cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionType:\n",
    "    VIEW = 'AT_View'\n",
    "    CLICK = 'AT_Click'\n",
    "    CART_UPDATE = 'AT_CartUpdate'\n",
    "    PURCHASE = 'AT_Purchase'\n",
    "\n",
    "\n",
    "class Preprocessor:\n",
    "    mapping_action_types = {\n",
    "        ActionType.VIEW: 0,\n",
    "        ActionType.CART_UPDATE: 1,\n",
    "        ActionType.CLICK: 2,\n",
    "        ActionType.PURCHASE: 3\n",
    "    }\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_df: pl.DataFrame,\n",
    "    ):\n",
    "        self.train_df = train_df\n",
    "\n",
    "    def _map_col(self, column: str, cast: pl.DataType = None) -> dict:\n",
    "        uniques = sorted(self.train_df.select(pl.col(column)).unique().to_series().to_list())\n",
    "        mapping = {val: idx for idx, val in enumerate(uniques)}\n",
    "\n",
    "        for attr in (\"train_df\",):\n",
    "            df = getattr(self, attr)\n",
    "            df = df.with_columns(\n",
    "                pl.col(column)\n",
    "                .replace(mapping)\n",
    "                .alias(column)\n",
    "            )\n",
    "            if cast is not None:\n",
    "                df = df.with_columns(pl.col(column).cast(cast))\n",
    "            setattr(self, attr, df)\n",
    "\n",
    "        return mapping\n",
    "\n",
    "    def run(self):\n",
    "        self.train_df = self.train_df.with_columns(\n",
    "            pl.col(\"source_type\").fill_null(\"\").alias(\"source_type\")\n",
    "        )\n",
    "\n",
    "        self.mapping_product_ids = self._map_col(\"product_id\")\n",
    "        self.mapping_user_ids = self._map_col(\"user_id\")\n",
    "        self.mapping_source_types = self._map_col(\"source_type\", cast=pl.Int8)\n",
    "\n",
    "        self.train_df = self.train_df.with_columns(\n",
    "            pl.col(\"action_type\")\n",
    "            .replace(self.mapping_action_types)\n",
    "            .cast(pl.Int8)\n",
    "            .alias(\"action_type\")\n",
    "        )\n",
    "\n",
    "        self.targets = (\n",
    "            self.train_df\n",
    "            .filter(\n",
    "                pl.col(\"request_id\").is_not_null() &\n",
    "                pl.col(\"action_type\").is_in([0, 1]) &\n",
    "                (pl.col(\"source_type\") != self.mapping_source_types[\"ST_Catalog\"])\n",
    "            )\n",
    "            .group_by([\n",
    "                \"user_id\",\n",
    "                \"request_id\",\n",
    "                \"product_id\",\n",
    "            ])\n",
    "            .agg([\n",
    "                pl.col(\"action_type\").max(),\n",
    "                pl.col(\"timestamp\").min(),\n",
    "                pl.col(\"source_type\").mode().first()\n",
    "            ])\n",
    "        )\n",
    "\n",
    "        requests_with_cartupdate_and_view = (\n",
    "            self.targets\n",
    "            .select([\"request_id\", \"action_type\", \"timestamp\"])\n",
    "            .group_by(\"request_id\")\n",
    "            .agg([\n",
    "                pl.col(\"action_type\").max().alias(\"max_t\"),\n",
    "                pl.col(\"action_type\").min().alias(\"min_t\"),\n",
    "                pl.len(),\n",
    "                pl.col(\"timestamp\").min().alias(\"req_ts\")\n",
    "            ])\n",
    "            .with_columns(sum_targets=pl.col('max_t').add(pl.col('min_t')))\n",
    "            .filter(pl.col('sum_targets') == 1)\n",
    "            .filter(pl.col('len') >= 10)\n",
    "            .select([\"request_id\", \"req_ts\"])\n",
    "        )\n",
    "        self.targets = (\n",
    "            self.targets\n",
    "            .drop(\"timestamp\")\n",
    "            .join(requests_with_cartupdate_and_view, on=\"request_id\", how=\"inner\")\n",
    "            .with_columns(pl.col(\"req_ts\").alias(\"timestamp\"))\n",
    "            .drop(\"req_ts\")\n",
    "        )\n",
    "        self.targets = (\n",
    "            self.targets\n",
    "            .group_by(['user_id', 'request_id', 'timestamp', 'source_type'])\n",
    "            .agg([\n",
    "                pl.col('product_id'),\n",
    "                pl.col('action_type'),\n",
    "            ])\n",
    "        )\n",
    "\n",
    "        self.timesplit_valid_end = self.train_df[\"timestamp\"].max()\n",
    "        self.timesplit_valid_start = self.timesplit_valid_end - 30 * 24 * 60 * 60\n",
    "        self.timesplit_train_end = self.timesplit_valid_start - 2 * 24 * 60 * 60\n",
    "        self.timesplit_train_start = self.train_df[\"timestamp\"].min()\n",
    "\n",
    "        self.train_df = (\n",
    "            self.train_df\n",
    "            .filter(pl.col(\"action_type\") != 0)\n",
    "            .drop(\"request_id\")\n",
    "        )\n",
    "        \n",
    "        self.train_targets = self.targets.filter(\n",
    "            pl.col(\"timestamp\") <= self.timesplit_train_end\n",
    "        )\n",
    "        self.valid_targets = self.targets.filter(\n",
    "            (pl.col(\"timestamp\") > self.timesplit_valid_start) &\n",
    "            (pl.col(\"timestamp\") <= self.timesplit_valid_end)\n",
    "        )\n",
    "        self.train_history = self.train_df.filter(pl.col('timestamp') <= self.timesplit_train_end)\n",
    "        self.valid_history = self.train_df.filter(pl.col('timestamp') > self.timesplit_train_end)\n",
    "\n",
    "        return (\n",
    "            self.train_history,\n",
    "            self.valid_history,\n",
    "            self.train_targets,\n",
    "            self.valid_targets\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3347dba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Preprocessor(train_df)\n",
    "train_history, valid_history, train_targets, valid_targets = preprocessor.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7ada58",
   "metadata": {},
   "source": [
    "- train_history/valid_history - позитивные взаимодействия пользователей\n",
    "- train_targets/valid_targets - группы для finetune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5773f69f",
   "metadata": {},
   "source": [
    "## 3. (1 балл) Подготовка данных для pretrain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c44cca",
   "metadata": {},
   "source": [
    "Для pretrain и finetune работа происходит с двумя последовательностями: последовательностью позитивных взаимодействий и последовательностью request-ов пользователя. Далее будем называть их history и candidates. На pretrain нам будет нужна только history. \n",
    "\n",
    "#### Обрезание историй\n",
    "\n",
    "У пользователей может быть разное количество позитивных событий в истории. Для простоты будет рассматривать последние 512 событий. Если вдруг их будет больше, то будем обрезать.\n",
    "\n",
    "#### Схемы таблиц и пример\n",
    "\n",
    "Схема для history имеет вид: \n",
    "```python\n",
    "HISTORY_SCHEMA = pl.Struct({\n",
    "    'source_type': pl.List(pl.Int64), \n",
    "    'action_type': pl.List(pl.Int64),\n",
    "    'product_id': pl.List(pl.Int64),\n",
    "    'position': pl.List(pl.Int64),\n",
    "    'targets_inds': pl.List(pl.Int64),\n",
    "    'targets_lengths': pl.List(pl.Int64), # количество таргет событий в истории\n",
    "    'lengths': pl.List(pl.Int64), # длина всей истории \n",
    "}).\n",
    "```\n",
    "`position` это индексы событий в истории (нужно будут далее для позиционных эмбеддингов), `targets_inds` - индексы тех позиций, которые будут участвовать в подсчете функции потерь. Они нужны, чтобы разделять потерю по событиям из обучающий и валидационной частей. `targets_lengths` - количество таких событий в истории. \n",
    "Пример: Пусть есть некоторый пользователь с историей из позитивных взаимодействий длины 5. Пусть первые 3 события попадают в обучение, а последние 2 в валидацию. Тогда:\n",
    "```python\n",
    "history_train_sample = pl.DataFrame({\n",
    "    'source_type': [1, 1, 2, 3, 4],\n",
    "    'action_type': [1, 0, 1, 0, 1],\n",
    "    'product_id': [1, 2, 3, 4, 5],\n",
    "    'position': [0, 1, 2, 3, 4],\n",
    "    'targets_inds': [0, 1, 2],\n",
    "    'targets_lengths': [3],\n",
    "    'lengths': [5]\n",
    "})\n",
    "history_valid_sample = pl.DataFrame({\n",
    "    'source_type': [1, 1, 2, 3, 4],\n",
    "    'action_type': [1, 0, 1, 0, 1],\n",
    "    'product_id': [1, 2, 3, 4, 5],\n",
    "    'position': [0, 1, 2, 3, 4],\n",
    "    'targets_inds': [3, 4],\n",
    "    'targets_lengths': [2],\n",
    "    'lengths': [5]\n",
    "})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6b6709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_sorted_by_timestamp(group: Iterable[Dict[str, Any]]) -> Generator[Dict[str, Any], None, None]:\n",
    "    \"\"\"\n",
    "    Ensures that the given iterable of events is sorted by the 'timestamp' field.\n",
    "\n",
    "    This function iterates over each event in the provided iterable and checks if the\n",
    "    'timestamp' of the current event is greater than or equal to the 'timestamp' of the\n",
    "    previous event. If any event has a 'timestamp' that is less than the previous event's\n",
    "    'timestamp', an AssertionError is raised.\n",
    "\n",
    "    @param group: An iterable of dictionaries, where each dictionary represents an event with at least a 'timestamp' key.\n",
    "    @return: A generator yielding each event from the input iterable in order, ensuring they are sorted by 'timestamp'.\n",
    "    @raises AssertionError: If the events are not sorted by 'timestamp'.\n",
    "    \"\"\"\n",
    "    # TODO: your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6949bd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mapper(ABC):\n",
    "    HISTORY_SCHEMA = pl.Struct({\n",
    "        'source_type': pl.List(pl.Int64), \n",
    "        'action_type': pl.List(pl.Int64),\n",
    "        'product_id': pl.List(pl.Int64),\n",
    "        'position': pl.List(pl.Int64),\n",
    "        'targets_inds': pl.List(pl.Int64),\n",
    "        'targets_lengths': pl.List(pl.Int64), # количество таргет событий в истории\n",
    "        'lengths': pl.List(pl.Int64), # длина всей истории \n",
    "    })\n",
    "    CANDIDATES_SCHEMA = pl.Struct({\n",
    "        'source_type': pl.List(pl.Int64), \n",
    "        'action_type': pl.List(pl.Int64),\n",
    "        'product_id': pl.List(pl.Int64),\n",
    "        'lengths': pl.List(pl.Int64), # длина каждого реквеста\n",
    "        'num_requests': pl.List(pl.Int64) # общее количество реквестов у этого пользователя\n",
    "    })\n",
    "\n",
    "    def __init__(self, min_length: int, max_length: int):\n",
    "        self._min_length: int = min_length\n",
    "        self._max_length: int = max_length\n",
    "\n",
    "    @abstractmethod\n",
    "    def __call__(self, group: pl.DataFrame) -> pl.DataFrame:\n",
    "        pass\n",
    "\n",
    "    def get_empty_frame(self, candidates=False):\n",
    "        return pl.DataFrame(schema=pl.Schema({\n",
    "            'history': self.HISTORY_SCHEMA,\n",
    "            **({'candidates': self.CANDIDATES_SCHEMA} if candidates else {})\n",
    "        }))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34414554",
   "metadata": {},
   "source": [
    "Реализуйте структуру, которая будет:\n",
    "- накапливать history для пользователя и оставлять последние `max_length`\n",
    "- уметь обращаться по индексу к событию истории\n",
    "- имеет метод `get(self, targets_ids)`, который будет превращать `self._data` в dict в соотвествии со схемой `HISTORY_SCHEMA` (см. history_train_sample, history_valid_sample)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c9597d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HistoryDeque:\n",
    "    def __init__(self, max_length):\n",
    "        self._data = deque([], maxlen=max_length)\n",
    "    \n",
    "    def append(self, x):\n",
    "        # TODO: your code here\n",
    "    \n",
    "    def __len__(self):\n",
    "        # TODO: your code here\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # TODO: your code here\n",
    "    \n",
    "    def get(self, targets_inds=None):\n",
    "        \"\"\"\n",
    "        Retrieves a dictionary containing various attributes of the dataset samples.\n",
    "\n",
    "        If `targets_inds` is not provided, it automatically identifies indices of samples where the `target` is 1.\n",
    "\n",
    "        @param targets_inds: List of indices of target samples. If None, it will be determined based on samples with target value 1.\n",
    "        @return: Dictionary with keys ['source_type', 'action_type', 'product_id', 'position', 'targets_inds', 'targets_lengths', 'lengths']\n",
    "                Each key maps to a list or value representing the respective attribute of the dataset samples.\n",
    "        \"\"\"\n",
    "        # TODO: your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cfc0dc",
   "metadata": {},
   "source": [
    "На основе функции `get_pretrain_data` реализуйте `PretrainMapper`, который будет по данном пользователю выдавать обучающий пример в нужном формате. Используйте `HistoryDeque` и `get_empty_frame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd0a3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PretrainMapper(Mapper):\n",
    "    def __call__(self, group: pl.DataFrame) -> pl.DataFrame:\n",
    "        \"\"\"\n",
    "        Processes a group of data by maintaining a history of rows up to a specified maximum length.\n",
    "        If the history meets the minimum length requirement and contains at least one target, it returns\n",
    "        a DataFrame with the history. Otherwise, it returns an empty DataFrame.\n",
    "\n",
    "        @param group: A Polars DataFrame containing the group of data to process.\n",
    "        @return: A Polars DataFrame containing the history if conditions are met; otherwise, an empty DataFrame.\n",
    "        \"\"\"\n",
    "        # TODO: your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d41d08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pretrain_data(train_history: pl.DataFrame,\n",
    "                      valid_history: pl.DataFrame,\n",
    "                      min_length: int = 5,\n",
    "                      max_length: int = 4096) -> pl.DataFrame:\n",
    "    mapper = PretrainMapper(\n",
    "        min_length=min_length,\n",
    "        max_length=max_length,\n",
    "    )\n",
    "\n",
    "    train_data = (\n",
    "        train_history.with_columns(target=pl.lit(1)) \n",
    "        .sort(['user_id', 'timestamp'])\n",
    "        .group_by('user_id')\n",
    "        .map_groups(mapper)\n",
    "    )\n",
    "\n",
    "    valid_data = (\n",
    "        pl.concat([\n",
    "            train_history.with_columns(target=pl.lit(0)), \n",
    "            valid_history.with_columns(target=pl.lit(1))\n",
    "        ], how='diagonal')\n",
    "        .sort(['user_id', 'timestamp'])\n",
    "        .group_by('user_id')\n",
    "        .map_groups(mapper)\n",
    "    )\n",
    "\n",
    "    return train_data, valid_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7d7425",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_train_data, pretrain_valid_data = get_pretrain_data(train_history, valid_history, min_length=5, max_length=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18672be",
   "metadata": {},
   "source": [
    "## 4. (1 балл) Реализуем свой torch.nn.utils.data.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2be818",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import polars as pl\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5764444",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dict_to_tensor(data_dict):\n",
    "    \"\"\"\n",
    "    Recursively converts lists within a dictionary to PyTorch tensors with dtype=torch.int64.\n",
    "    \n",
    "    @param data_dict: A dictionary potentially containing nested dictionaries and lists.\n",
    "    @return: A new dictionary with the same structure as `data_dict`, but with lists converted to PyTorch tensors.\n",
    "    \"\"\"\n",
    "    # TODO: your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc80b148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_convert_dict_to_tensor_basic():\n",
    "    input_data = {\n",
    "        'a': [1, 2, 3],\n",
    "        'b': {\n",
    "            'c': [4, 5],\n",
    "            'd': 6\n",
    "        },\n",
    "        'e': 'text'\n",
    "    }\n",
    "\n",
    "    result = convert_dict_to_tensor(input_data)\n",
    "\n",
    "    assert isinstance(result['a'], torch.Tensor)\n",
    "    assert result['a'].dtype == torch.int64\n",
    "    assert result['a'].tolist() == [1, 2, 3]\n",
    "\n",
    "    assert isinstance(result['b'], dict)\n",
    "    assert isinstance(result['b']['c'], torch.Tensor)\n",
    "    assert result['b']['c'].dtype == torch.int64\n",
    "    assert result['b']['c'].tolist() == [4, 5]\n",
    "\n",
    "    assert result['b']['d'] == 6\n",
    "    assert result['e'] == 'text'\n",
    "\n",
    "test_convert_dict_to_tensor_basic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f256020",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LavkaDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    @classmethod\n",
    "    def from_dataframe(cls, df: pl.DataFrame) -> 'LavkaDataset':\n",
    "        # TODO: your code here, use convert_dict_to_tensor\n",
    "    \n",
    "    def __len__(self):\n",
    "        # TODO: your code here\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # TODO: your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b9e3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating train dataset ...\")\n",
    "train_ds = LavkaDataset.from_dataframe(pretrain_train_data)\n",
    "print(\"Creating valid dataset ...\")\n",
    "valid_ds = LavkaDataset.from_dataframe(pretrain_valid_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96837a5f",
   "metadata": {},
   "source": [
    "## 5. (2 балл) Реализуем основной backbone модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b0263e",
   "metadata": {},
   "source": [
    "**Нигде далее при реализации моделей циклы использовать нельзя. Структуру кода везде можно менять без нарушения логики.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11db0387",
   "metadata": {},
   "source": [
    "Реализуйте класс ResNet-блока согласно следующим формулам:\n",
    "\n",
    "Для входа $x\\in\\mathbb{R}^{\\text{batch}\\times d}$ вычислить:  \n",
    "$$\n",
    "    \\begin{aligned}\n",
    "    z &= xW + b,\\\\\n",
    "    a &= \\mathrm{ReLU}(z),\\\\\n",
    "    d'&= \\mathrm{Dropout}(a),\\\\\n",
    "    y &= \\mathrm{LayerNorm}\\bigl(x + d'\\bigr).\n",
    "    \\end{aligned}\n",
    "$$  \n",
    "В компактном виде:  \n",
    "$$\n",
    "    y = \\mathrm{LayerNorm}\\Bigl(x + \\mathrm{Dropout}\\bigl(\\mathrm{ReLU}(xW + b)\\bigr)\\Bigr)\\,.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756010dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, embedding_dim, dropout=0.):\n",
    "        super().__init__()\n",
    "        # TODO: your code here\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb46dcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_resnet_output_shape():\n",
    "    embedding_dim = 32\n",
    "    batch_size = 8\n",
    "    model = ResNet(embedding_dim)\n",
    "    x = torch.randn(batch_size, embedding_dim)\n",
    "    out = model(x)\n",
    "    assert out.shape == (batch_size, embedding_dim)\n",
    "    \n",
    "test_resnet_output_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6016c09a",
   "metadata": {},
   "source": [
    "Реализуйте `ContextEncoder`, `ItemEncoder` и `ActionEncoder`. На вход они принмают torch.tensor с индексами размера (seq_len,), а на выходе должны получить torch.tensor с соотвествующими векторами размера (seq_len, embedding_dim). Для `nn.Embedding` нужно будет подсчитать количество уникальных индексов для каждого типа. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf716125",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextEncoder(nn.Module):\n",
    "    def __init__(self, embedding_dim=64):\n",
    "        super().__init__()\n",
    "        # TODO: your code here\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # TODO: your code here\n",
    "\n",
    "\n",
    "class ItemEncoder(nn.Module):\n",
    "    def __init__(self, embedding_dim=64):\n",
    "        super().__init__()\n",
    "        # TODO: your code here\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # TODO: your code here\n",
    "\n",
    "\n",
    "class ActionEncoder(nn.Module):\n",
    "    def __init__(self, embedding_dim=64):\n",
    "        super().__init__()\n",
    "        # TODO: your code here\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        # TODO: your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111d85db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_context_encoder_shape():\n",
    "    embedding_dim = 16\n",
    "    batch_size = 5\n",
    "    seq_len = 7\n",
    "    model = ContextEncoder(embedding_dim=embedding_dim)\n",
    "    x = torch.randint(0, 4, (batch_size, seq_len))\n",
    "    out = model(x)\n",
    "    assert out.shape == (batch_size, seq_len, embedding_dim)\n",
    "test_context_encoder_shape()\n",
    "\n",
    "def test_item_encoder_shape():\n",
    "    embedding_dim = 20\n",
    "    batch_size = 6\n",
    "    seq_len = 10\n",
    "    model = ItemEncoder(embedding_dim=embedding_dim)\n",
    "    x = torch.randint(0, 20000, (batch_size, seq_len))\n",
    "    out = model(x)\n",
    "    assert out.shape == (batch_size, seq_len, embedding_dim)\n",
    "test_item_encoder_shape()\n",
    "\n",
    "def test_action_encoder_shape():\n",
    "    embedding_dim = 12\n",
    "    batch_size = 4\n",
    "    seq_len = 3\n",
    "    model = ActionEncoder(embedding_dim=embedding_dim)\n",
    "    x = torch.randint(0, 4, (batch_size, seq_len))\n",
    "    out = model(x)\n",
    "    assert out.shape == (batch_size, seq_len, embedding_dim)\n",
    "test_action_encoder_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24183263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(lengths):\n",
    "    \"\"\"\n",
    "    Generates a mask tensor based on the given sequence lengths.\n",
    "\n",
    "    The mask is a boolean tensor where each row corresponds to a sequence and contains\n",
    "    True values up to the length of the sequence and False values thereafter.\n",
    "\n",
    "    @param lengths: A 1D tensor containing the lengths of sequences.\n",
    "    @return: A 2D boolean tensor where each row has True up to the corresponding sequence length.\n",
    "    \"\"\"\n",
    "    # TODO: your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa156c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_get_mask():\n",
    "    lengths = torch.tensor([2, 3, 1])\n",
    "    expected_mask = torch.tensor([\n",
    "        [True, True, False],\n",
    "        [True, True, True],\n",
    "        [True, False, False]\n",
    "    ])\n",
    "    assert torch.equal(get_mask(lengths), expected_mask)\n",
    "\n",
    "test_get_mask()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f63da84",
   "metadata": {},
   "source": [
    "Далее нужно реализовать `ModelBackbone`. Эта часть модели является общей для pretrain и finetune. Она кодируется входные события, преобразует их в нужный для трансформера формат `(batch_size, seq_len, embedding_dim)`, прогоняет через них трансформер и возвращает три поля: выходы трансформера, вектора товаров и вектора feedback-ов.\n",
    "\n",
    "Трансформер применяем с каузальной маской. Не забудьте про кодирование позиций. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f5edfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelBackbone(nn.Module):\n",
    "    def __init__(self, \n",
    "                 embedding_dim=64,\n",
    "                 num_heads=2,\n",
    "                 max_seq_len=512,\n",
    "                 dropout_rate=0.2,\n",
    "                 num_transformer_layers=2):\n",
    "        super().__init__()\n",
    "        self.context_encoder = # TODO: your code here\n",
    "        self.item_encoder = # TODO: your code here\n",
    "        self.action_encoder = # TODO: your code here\n",
    "        self.position_embeddings = # TODO: your code here\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embedding_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=embedding_dim * 4,\n",
    "            dropout=dropout_rate,\n",
    "            activation='gelu',\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_transformer_layers)\n",
    "        self._embedding_dim = embedding_dim\n",
    "    \n",
    "    @property\n",
    "    def embedding_dim(self):\n",
    "        return self._embedding_dim\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        context_embeddings = # TODO: your code here\n",
    "        item_embeddings = # TODO: your code here\n",
    "        action_embeddings = # TODO: your code here\n",
    "\n",
    "        padding_mask = # TODO: your code here\n",
    "        batch_size, seq_len = padding_mask.shape\n",
    "\n",
    "        token_embeddings = item_embeddings.new_zeros(\n",
    "            batch_size, seq_len, self.embedding_dim\n",
    "        )\n",
    "        token_embeddings[padding_mask] = # TODO: your code here\n",
    "\n",
    "        # apply transformer encoder\n",
    "        source_embeddings = # TODO: your code here\n",
    "\n",
    "        return {\n",
    "            'source_embeddings': source_embeddings,\n",
    "            'item_embeddings': item_embeddings,\n",
    "            'context_embeddings': context_embeddings\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b07d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_backbone():\n",
    "    sample = {\n",
    "        'history': {\n",
    "            'source_type': torch.tensor([1, 1, 7, 1, 1]), \n",
    "            'action_type': torch.tensor([2, 2, 2, 1, 2]), \n",
    "            'product_id': torch.tensor([19210,  8368,  5165,  5326, 12476]), \n",
    "            'position': torch.tensor([0, 1, 2, 3, 4]), \n",
    "            'targets_inds': torch.tensor([0, 1, 2]), \n",
    "            'targets_lengths': torch.tensor([3]), \n",
    "            'lengths': torch.tensor([5])\n",
    "        }\n",
    "    }\n",
    "    backbone = ModelBackbone()\n",
    "    output = backbone(sample)\n",
    "    assert output['source_embeddings'].shape == (5, 64)\n",
    "    assert output['item_embeddings'].shape == (5, 64)\n",
    "    assert output['context_embeddings'].shape == (5, 64)\n",
    "test_model_backbone()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d87649",
   "metadata": {},
   "source": [
    "## 6. (2 балл) Реализуем pretrain модель"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95f2cf2",
   "metadata": {},
   "source": [
    "#### Головы (heads)\n",
    "\n",
    "- **User–context fusion**  \n",
    "      Последовательность ResNet-блоков, свёртка размерности `2D → D`. На входе конкатенация `source_embeddings ∥ context_embeddings`.  \n",
    "- **Candidate projector**  \n",
    "      Три ResNet-блока, преобразующие эмбеддинг товара из `D → D`.  \n",
    "- **Classifier**  \n",
    "      Три ResNet-блока, затем линейный слой `3D → 3`, для предсказания типа следующего действия из трёх возможных (cart, click, purchase).  \n",
    "- **Параметр τ**  \n",
    "      Скаляp-коэффициент `τ = clip(exp(τ_raw), τ_min, τ_max)` для масштабирования скалярных произведений – температура в contrastive-лоссе.\n",
    "\n",
    "\n",
    "#### Формулы лоссов\n",
    "\n",
    "Обозначения:  \n",
    "- $u_i \\in \\mathbb{R}^D$ – нормализованный вектор пользователя для i-го примера.  \n",
    "- $c_i \\in \\mathbb{R}^D$ – нормализованный вектор кандидата (позитивного товара) для i-го примера.  \n",
    "- $\\{n_{ij}\\}_{j=1}^M\\subset\\mathbb{R}^D$ – нормализованные векторы $M$ негативных товаров (весь каталог товаров).  \n",
    "- $\\tau>0$ – «температура» (скаляр).  \n",
    "- $K= M+1$ – общее число кандидатов (1 позитивный + M негативных).\n",
    "\n",
    "1. **Retrieval loss** (контрастивный softmax-лосс)  \n",
    "   Для каждого примера $i$ вычисляем скалярные логиты:  \n",
    "   $$\n",
    "     \\ell_i = [\\,\\underbrace{u_i^\\top c_i}_{\\text{позитивный логит}} \\,\\big|\\,\n",
    "               \\underbrace{u_i^\\top n_{i1},\\,u_i^\\top n_{i2},\\,\\dots,\\,u_i^\\top n_{iM}}_{\\text{негативные логиты}}] \\;\\times\\;\\tau\n",
    "   $$\n",
    "   Затем лосс  \n",
    "   $$\n",
    "     \\mathcal{L}_{\\mathrm{retr}} \n",
    "     = -\\frac1N \\sum_{i=1}^N \\log\\frac{\\exp\\bigl(u_i^\\top c_i \\,\\tau\\bigr)}\n",
    "                                      {\\exp\\bigl(u_i^\\top c_i \\,\\tau\\bigr)\n",
    "                                     + \\sum_{j=1}^M \\exp\\bigl(u_i^\\top n_{ij}\\,\\tau\\bigr)}.\n",
    "   $$\n",
    "\n",
    "2. **Action loss** (кросс-энтропия)  \n",
    "   Для каждого положительного шага $i$ модель выдаёт логиты $\\mathbf{z}_i \\in \\mathbb{R}^3$ по трём классам действий, а истинная метка $y_i\\in\\{0,1,2\\}$.  \n",
    "   $$\n",
    "     \\mathcal{L}_{\\mathrm{action}} \n",
    "     = -\\frac1N \\sum_{i=1}^N \\sum_{k=0}^2 \\delta_{y_i=k}\\,\\log\\bigl(\\mathrm{softmax}(\\mathbf{z}_i)_k\\bigr),\n",
    "   $$\n",
    "   где $\\mathrm{softmax}(\\mathbf{z})_k = \\frac{e^{z_k}}{\\sum_{m=0}^2 e^{z_m}}$.\n",
    "\n",
    "3. **Итоговый лосс**  \n",
    "   $$\n",
    "     \\mathcal{L} \n",
    "     = \\mathcal{L}_{\\mathrm{retr}} \n",
    "       \\;+\\; 10 \\times \\mathcal{L}_{\\mathrm{action}}.\n",
    "   $$\n",
    "   Перевзвешиваем action часть т.к. у нее сильно меньше масштаб.\n",
    "\n",
    "#### Подсказки\n",
    "Используйте `tensor.roll` и `tensor.log_softmax`, `torch.repeat_interleave`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250b7f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PretrainModel(nn.Module):\n",
    "    MIN_TEMPERATURE = 0.01\n",
    "    MAX_TEMPERATURE = 100\n",
    "    \n",
    "    def __init__(self,\n",
    "                 backbone,\n",
    "                 embedding_dim=64):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone \n",
    "        self.user_context_fusion = nn.Sequential(\n",
    "            ResNet(2 * embedding_dim),\n",
    "            ResNet(2 * embedding_dim),\n",
    "            ResNet(2 * embedding_dim),\n",
    "            nn.Linear(2 * embedding_dim, embedding_dim),\n",
    "        )\n",
    "        self.candidate_projector = nn.Sequential(\n",
    "            ResNet(embedding_dim),\n",
    "            ResNet(embedding_dim),\n",
    "            ResNet(embedding_dim),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            ResNet(3 * embedding_dim),\n",
    "            ResNet(3 * embedding_dim),\n",
    "            ResNet(3 * embedding_dim),\n",
    "            nn.Linear(3 * embedding_dim, 3),\n",
    "        )\n",
    "        self._embedding_dim = embedding_dim\n",
    "        self.tau = torch.nn.Parameter(torch.zeros(1, dtype=torch.float32))\n",
    "    \n",
    "    @property\n",
    "    def embedding_dim(self):\n",
    "        return self._embedding_dim\n",
    "\n",
    "    @property\n",
    "    def temperature(self):\n",
    "        return torch.clip(torch.exp(self.tau), min=self.MIN_TEMPERATURE, max=self.MAX_TEMPERATURE)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        backbone_outputs = # TODO: your code here\n",
    "        source_embeddings = # TODO: your code here\n",
    "        item_embeddings = # TODO: your code here\n",
    "        context_embeddings = # TODO: your code here\n",
    "\n",
    "        lengths = # TODO: your code here\n",
    "        offsets = # TODO: your code here\n",
    "        target_mask = # TODO: your code here\n",
    "        target_inds = # TODO: your code here\n",
    "        target_mask[target_inds] = # TODO: your code here\n",
    "\n",
    "        non_first_element = # TODO: your code here\n",
    "        non_first_element[offsets - lengths] = # TODO: your code here\n",
    "        non_first_element &= # TODO: your code here\n",
    "        source_mask = # TODO: your code here\n",
    "\n",
    "        source_embeddings = source_embeddings[source_mask]\n",
    "        context_embeddings = context_embeddings[non_first_element]\n",
    "        item_embeddings = item_embeddings[non_first_element]\n",
    "        \n",
    "        # calc retrieval loss\n",
    "        user_embeddings = torch.nn.functional.normalize(# TODO: your code here)\n",
    "        candidate_embeddings = torch.nn.functional.normalize(# TODO: your code here)\n",
    "        negative_embeddings = torch.nn.functional.normalize(# TODO: your code here)\n",
    "        pos_logits = # TODO: your code here\n",
    "        neg_logits = # TODO: your code here\n",
    "        next_positive_prediction_loss = # TODO: your code here\n",
    "\n",
    "        # calc action loss\n",
    "        logits = # TODO: your code here \n",
    "        targets = # TODO: your code here\n",
    "        feedback_prediction_loss = # TODO: your code here\n",
    "\n",
    "        return {\n",
    "            'next_positive_prediction_loss': next_positive_prediction_loss,\n",
    "            'feedback_prediction_loss': feedback_prediction_loss,\n",
    "            'loss': next_positive_prediction_loss + feedback_prediction_loss * 10\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ff38e6",
   "metadata": {},
   "source": [
    "## 7. (0.5 балл) Обучим pretrain модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98d2b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Collates a batch of samples from a dataset.\n",
    "\n",
    "    This function is designed to handle batches where each sample is a dictionary.\n",
    "    It recursively collates values associated with the same keys across all samples in the batch.\n",
    "    For tensor values, it concatenates them along the first dimension.\n",
    "    For dictionary values, it applies the same collation logic recursively.\n",
    "    For other types of values, it simply aggregates them into a list.\n",
    "\n",
    "    @param batch: A list of samples, where each sample is a dictionary.\n",
    "    @return: A dictionary with the same keys as the samples, where each value is either\n",
    "             a concatenated tensor, a recursively collated dictionary, or a list of values.\n",
    "    \"\"\"\n",
    "    # TODO: your code here \n",
    "\n",
    "\n",
    "def move_to_device(batch, device):\n",
    "    \"\"\"\n",
    "    Moves a batch of data to a specified device (e.g., CPU or GPU).\n",
    "\n",
    "    Args:\n",
    "        batch (torch.Tensor or dict): The batch of data to move. Can be a single tensor or a dictionary of tensors.\n",
    "        device (torch.device): The target device to which the batch should be moved.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor or dict: The batch of data moved to the specified device. \n",
    "                             If the input is a dictionary, the returned value will be a dictionary with the same keys \n",
    "                             and values moved to the specified device.\n",
    "    \"\"\"\n",
    "    # TODO: your code here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5077c9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_collate_fn_basic():\n",
    "    batch = [\n",
    "        {\n",
    "            'x': torch.tensor([1, 2]),\n",
    "            'y': {\n",
    "                'z': torch.tensor([[10], [20]]),\n",
    "                'w': 5\n",
    "            },\n",
    "            's': 'foo'\n",
    "        },\n",
    "        {\n",
    "            'x': torch.tensor([3, 4]),\n",
    "            'y': {\n",
    "                'z': torch.tensor([[30], [40]]),\n",
    "                'w': 6\n",
    "            },\n",
    "            's': 'bar'\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    result = collate_fn(batch)\n",
    "\n",
    "    assert isinstance(result['x'], torch.Tensor)\n",
    "    assert result['x'].tolist() == [1, 2, 3, 4]\n",
    "\n",
    "    assert isinstance(result['y'], dict)\n",
    "    assert isinstance(result['y']['z'], torch.Tensor)\n",
    "    assert result['y']['z'].tolist() == [[10], [20], [30], [40]]\n",
    "    assert result['y']['w'] == [5, 6]\n",
    "\n",
    "    assert result['s'] == ['foo', 'bar']\n",
    "test_collate_fn_basic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef41d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "\n",
    "def train_pretrain_model(model, train_loader, valid_loader, optimizer, scheduler, num_epochs, device):\n",
    "    global_cnt = 0\n",
    "    prev_valid_loss = None\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_losses = [] \n",
    "        action_losses = []\n",
    "        retrieval_losses = []\n",
    "        for batch in tqdm(train_loader):\n",
    "            batch = move_to_device(batch, device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(batch)\n",
    "            loss = output['loss']\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "            action_losses.append(output['feedback_prediction_loss'].item())\n",
    "            retrieval_losses.append(output['next_positive_prediction_loss'].item())\n",
    "        scheduler.step()\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {mean(train_losses):.6f}, Train Feedback Loss: {mean(action_losses):.6f}, Train NPP Loss: {mean(retrieval_losses):.6f}\")\n",
    "\n",
    "        model.eval()\n",
    "        valid_losses = []\n",
    "        action_losses = []\n",
    "        retrieval_losses = []\n",
    "        with torch.inference_mode():\n",
    "            for batch in tqdm(valid_loader):\n",
    "                batch = move_to_device(batch, device)\n",
    "                output = model(batch)\n",
    "                loss = output['loss']\n",
    "                valid_losses.append(loss.item())\n",
    "                action_losses.append(output['feedback_prediction_loss'].item())\n",
    "                retrieval_losses.append(output['next_positive_prediction_loss'].item())\n",
    "\n",
    "        avg_valid_loss = mean(valid_losses)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Valid Loss: {avg_valid_loss:.6f}, Valid Feedback Loss: {mean(action_losses):.6f}, Valid NPP Loss: {mean(retrieval_losses):.6f}\")\n",
    "        \n",
    "        if prev_valid_loss is None or prev_valid_loss > avg_valid_loss:\n",
    "            global_cnt = 0\n",
    "            prev_valid_loss = avg_valid_loss\n",
    "            with torch.no_grad():\n",
    "                torch.save(model, './pretrain.pt')\n",
    "        else:\n",
    "            global_cnt += 1\n",
    "            if global_cnt == 10:\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4befdc1c",
   "metadata": {},
   "source": [
    "Параметры и инициализацию можно менять для пробития порогов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afde462",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "batch_size = 4\n",
    "warmup_epochs = 3\n",
    "start_factor = 0.1\n",
    "num_epochs = 100\n",
    "\n",
    "embedding_dim = 64\n",
    "num_heads = 2\n",
    "max_seq_len = 512\n",
    "dropout_rate = 0.1\n",
    "num_transformer_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb8af26",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = # TODO: your code here \n",
    "valid_loader = # TODO: your code here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c8d4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "backbone = # TODO: your code here \n",
    "model_pretrain = # TODO: your code here \n",
    "optimizer = optim.AdamW(model_pretrain.parameters(), lr=lr, weight_decay=0.01)\n",
    "scheduler = optim.lr_scheduler.LinearLR(\n",
    "    optimizer,\n",
    "    start_factor=start_factor,\n",
    "    total_iters=warmup_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8506243",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pretrain_model(model_pretrain, train_loader, valid_loader, optimizer, scheduler, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e66695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pretrain_model(valid_loader):\n",
    "    test_model = torch.load('./pretrain.pt', weights_only=False)\n",
    "    valid_losses = []\n",
    "    with torch.inference_mode():\n",
    "        for batch in tqdm(valid_loader):\n",
    "            batch = move_to_device(batch, device)\n",
    "            output = test_model(batch)\n",
    "            loss = output['loss']\n",
    "            valid_losses.append(loss.item())\n",
    "    assert mean(valid_losses) < 11.7\n",
    "\n",
    "test_pretrain_model(valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b660b6c",
   "metadata": {},
   "source": [
    "## 8. (1 балл) Подготовка данных для finetune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2366cc6",
   "metadata": {},
   "source": [
    "Схемы для candidates:\n",
    "```python\n",
    "CANDIDATES_SCHEMA = pl.Struct({\n",
    "    'source_type': pl.List(pl.Int64), \n",
    "    'action_type': pl.List(pl.Int64),\n",
    "    'product_id': pl.List(pl.Int64),\n",
    "    'lengths': pl.List(pl.Int64), # длина каждого реквеста\n",
    "    'num_requests': pl.List(pl.Int64) # общее количество реквестов у этого пользователя\n",
    "})\n",
    "```\n",
    "\n",
    "Пример семпла:\n",
    "\n",
    "```python\n",
    "finetune_train_sample = {\n",
    "    'history': {...},\n",
    "    'candidates': {\n",
    "        'source_type': [1, 2, 3],\n",
    "        'action_type': [1, 0, 1, 0, 1, 0, 1, 1, 1],\n",
    "        'product_id': [10, 20, 30, 40, 50, 60, 70, 80, 90],\n",
    "        'lengths': [3, 3, 3],\n",
    "        'num_requests': 3\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fea941",
   "metadata": {},
   "source": [
    "Аналогично реализуйте структуру для candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b77da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Candidates:\n",
    "    def __init__(self, max_requests_size):\n",
    "        self._data = deque([], maxlen=max_requests_size) \n",
    "    \n",
    "    def append(self, x):\n",
    "        # TODO: your code here \n",
    "    \n",
    "    def popleft(self):\n",
    "        # TODO: your code here \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # TODO: your code here \n",
    "    \n",
    "    def __len__(self):\n",
    "        # TODO: your code here \n",
    "    \n",
    "    def get(self):\n",
    "       \"\"\"\n",
    "        Aggregates data from the internal _data attribute into a structured dictionary format.\n",
    "\n",
    "        This method constructs a dictionary with keys 'source_type', 'action_type', 'product_id', 'lengths', and 'num_requests'.\n",
    "        - 'source_type' contains the source types from each sample.\n",
    "        - 'action_type' contains all action types from each sample's action_type_list flattened into a single list.\n",
    "        - 'product_id' contains all product IDs from each sample's product_id_list flattened into a single list.\n",
    "        - 'lengths' contains the length of the product_id_list for each sample.\n",
    "        - 'num_requests' contains the total number of samples.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, Any]: A dictionary with aggregated data.\n",
    "        \"\"\" \n",
    "        # TODO: your code here "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb9cb27",
   "metadata": {},
   "source": [
    "При реализации `FinetuneTrainMapper` и `FinetuneValidMapper` отличие будет только в формировании targets_inds. В первом случае это может быть некоторая произвольная последовательность индексов, т.к. присутсвует случайность. Во втором случае это всегда будет последовательность из просто одного и того же последнего индекса.\n",
    "\n",
    "`FinetuneTrainMapper` можно реализовать за O(N^2) от длины candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13bb58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "class FinetuneTrainMapper(Mapper):\n",
    "    def __call__(self, group: pl.DataFrame) -> pl.DataFrame:\n",
    "        \"\"\"\n",
    "        Processes a group of interactions to generate history and candidate sets for recommendation.\n",
    "\n",
    "        This method processes a DataFrame containing interaction data, separating actions into history and candidates based on the presence of 'action_type_list'.\n",
    "        It ensures the data is sorted by timestamp, filters candidates based on time constraints, and selects historical interactions within a specified lag range for each candidate.\n",
    "        If there are no valid candidates or insufficient history, it returns an empty DataFrame.\n",
    "\n",
    "        @param group: A Polars DataFrame containing interaction data with at least 'timestamp' and 'action_type_list' columns.\n",
    "        @return: A Polars DataFrame with 'history' and 'candidates' columns, or an empty DataFrame if no valid candidates are found.\n",
    "        \"\"\"\n",
    "        # TODO: your code here \n",
    "        \n",
    "\n",
    "class FinetuneValidMapper(Mapper):\n",
    "    def __call__(self, group: pl.DataFrame) -> pl.DataFrame:\n",
    "        \"\"\"\n",
    "        Differs only in the formation of target_inds\n",
    "        \"\"\"\n",
    "        # TODO: your code here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707cfdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_finetune_data(train_history: pl.DataFrame,\n",
    "                      train_targets: pl.DataFrame,\n",
    "                      valid_targets: pl.DataFrame,\n",
    "                      min_length: int = 5,\n",
    "                      max_length: int = 4096) -> pl.DataFrame:\n",
    "    mapper = FinetuneTrainMapper(\n",
    "        min_length=min_length,\n",
    "        max_length=max_length,\n",
    "    )\n",
    "\n",
    "    train_data = (\n",
    "        pl.concat([\n",
    "            train_history,\n",
    "            train_targets.with_columns([\n",
    "                pl.col('product_id').alias('product_id_list'), \n",
    "                pl.col('action_type').alias('action_type_list')\n",
    "            ]).drop(['product_id', 'action_type'])\n",
    "        ], how='diagonal')\n",
    "        .sort(['user_id', 'timestamp'])\n",
    "        .group_by('user_id')\n",
    "        .map_groups(mapper)\n",
    "    )\n",
    "\n",
    "    mapper = FinetuneValidMapper(\n",
    "        min_length=min_length,\n",
    "        max_length=max_length,\n",
    "    )\n",
    "\n",
    "    valid_data = (\n",
    "        pl.concat([\n",
    "            train_history,\n",
    "            valid_targets.with_columns([\n",
    "                pl.col('product_id').alias('product_id_list'), \n",
    "                pl.col('action_type').alias('action_type_list')\n",
    "            ]).drop(['product_id', 'action_type'])\n",
    "        ], how='diagonal')\n",
    "        .sort(['user_id', 'timestamp'])\n",
    "        .group_by('user_id')\n",
    "        .map_groups(mapper)\n",
    "    )\n",
    "\n",
    "    return train_data, valid_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f663b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_train_data, finetune_valid_data = get_finetune_data(train_history, train_targets, valid_targets, min_length=5, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75788228",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating train dataset ...\")\n",
    "train_ds = LavkaDataset.from_dataframe(finetune_train_data)\n",
    "print(\"Creating valid dataset ...\")\n",
    "valid_ds = LavkaDataset.from_dataframe(finetune_valid_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344bdfff",
   "metadata": {},
   "source": [
    "## 9. (2 балл) Реализуем finetune модель"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbd0611",
   "metadata": {},
   "source": [
    "#### Функция make_groups: разметка элементов по «группам»\n",
    "\n",
    "Дано: вектор длин последовательностей  \n",
    "$$\n",
    "\\mathbf{l} = [\\,l_1, l_2, \\dots, l_B\\,],\\quad l_i\\in\\mathbb{N},\\;\n",
    "B=\\text{batch size}.\n",
    "$$  \n",
    "Нужно получить вектор «номеров групп» длиной  \n",
    "$$\n",
    "N = \\sum_{i=1}^B l_i\n",
    "$$\n",
    "так, чтобы первые $l_1$ элементов имели номер группы 0, следующие $l_2$ - номер 1 и т.д.  \n",
    "Результат:  \n",
    "$$\n",
    "\\mathrm{groups} = [\\,\\underbrace{0,\\dots,0}_{l_1},\\;\n",
    "\\underbrace{1,\\dots,1}_{l_2},\\;\\dots\\;,\\underbrace{B-1,\\dots,B-1}_{l_B}\\,]\\,.\n",
    "$$\n",
    "\n",
    "Циклы использовать нельзя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdaabe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_groups(lengths: torch.Tensor) -> torch.Tensor:\n",
    "    # TODO: your code here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee5be06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_make_groups_basic():\n",
    "    lengths = torch.tensor([2, 3, 1])\n",
    "    expected = torch.tensor([0, 0, 1, 1, 1, 2])\n",
    "    result = make_groups(lengths)\n",
    "    assert torch.equal(result, expected)\n",
    "    \n",
    "test_make_groups_basic()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925b500d",
   "metadata": {},
   "source": [
    "#### Функция make_pairs: построение всех упорядоченных пар внутри групп\n",
    "\n",
    "Цель: для каждого «блока» длины $l_i$ сгенерировать всех $l_i\\times l_i$ упорядоченных пар индексов  \n",
    "$$\n",
    "( p, q ),\\quad p,q\\in\\{0,\\dots,l_i-1\\},\n",
    "$$\n",
    "а затем «развернуть» их по всему батчу. Результат - двумерный тензор shape $(2,\\,\\sum_i l_i^2)$, где\n",
    "\n",
    "- первая строка `pairs` - индексы «первого» элемента пары в пределах своего блока,  \n",
    "- вторая строка `pairs` - индексы «второго».\n",
    "\n",
    "Математически пары нумеруются так:\n",
    "$$\n",
    "\\{\\, (p,q)\\;\\big|\\;p=0..l_i-1,\\;q=0..l_i-1\\;\\}\\quad\\forall i=1..B.\n",
    "$$\n",
    "Используйте scatter_add:  \n",
    "- один - чтобы повторить номер группы и получить `first`,  \n",
    "- другой - чтобы вычислить смещение для `second`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92121880",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pairs(lengths: torch.Tensor) -> torch.Tensor:\n",
    "    # TODO: your code here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cebd057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_make_pairs_simple():\n",
    "    lengths = torch.tensor([1, 2], dtype=torch.long)\n",
    "    expected = torch.tensor([\n",
    "        [0, 1, 1, 2, 2],\n",
    "        [0, 1, 2, 1, 2]\n",
    "    ], dtype=torch.long)\n",
    "\n",
    "    pairs = make_pairs(lengths)\n",
    "    assert pairs.shape == (2, 5)\n",
    "    assert torch.equal(pairs, expected)\n",
    "\n",
    "test_make_pairs_simple()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d085421",
   "metadata": {},
   "source": [
    "#### Класс CalibratedPairwiseLogistic: попарная калиброванная логистическая функция потерь\n",
    "\n",
    "Идея была предложена здесь: [Calibrated Pairwise Logistic](https://arxiv.org/pdf/2211.01494). Пусть у нас есть:\n",
    "\n",
    "- логиты всех элементов: $\\mathbf{c} \\in \\mathbb{R}^N$,\n",
    "- таргеты $\\mathbf{t}\\in\\mathbb{R}^N$,\n",
    "\n",
    "Шаги:\n",
    "\n",
    "1. Генерируем все упорядоченные пары индексов внутри групп:  \n",
    "   $$\n",
    "   \\mathrm{pairs} = \\bigl[\\;I_0,\\;I_1\\bigr],\\quad\n",
    "   I_0,I_1\\in\\{0,\\dots,N-1\\}\n",
    "   $$\n",
    "2. Для каждой пары извлекаем  \n",
    "   $$\n",
    "   c_i = c_{I_0},\\quad c_j = c_{I_1},\\quad\n",
    "   t_i = t_{I_0},\\quad t_j = t_{I_1}.\n",
    "   $$\n",
    "3. Отбираем только «положительные» пары, где $t_i > t_j$. Вводим индикатор  \n",
    "   $$\n",
    "   w_{ij} = \n",
    "     \\begin{cases}\n",
    "       1,&t_i > t_j,\\\\\n",
    "       0,&\\text{иначе}.\n",
    "     \\end{cases}\n",
    "   $$\n",
    "   И считаем $W=\\sum w_{ij}$.\n",
    "4. Если $W>0$, вычисляем попарный loss для каждой положительной пары:\n",
    "   \n",
    "   а) сначала вычисляем «калиброванную вероятность» того, что $i$ лучше $j$:\n",
    "   $$\n",
    "     p_{ij}\n",
    "     = \\frac{\\sigma(c_i)}{\\sigma(c_i)+\\sigma(c_j)},\n",
    "     \\quad\n",
    "     \\sigma(x)=\\frac1{1+e^{-x}}.\n",
    "   $$\n",
    "   б) берём отрицательный логарифм правдоподобия:\n",
    "   $$\n",
    "     \\ell_{ij}\n",
    "     = -\\log p_{ij}\n",
    "     = -\\log\\frac{\\sigma(c_i)}{\\sigma(c_i)+\\sigma(c_j)}.\n",
    "   $$\n",
    "   \n",
    "5. Итоговая loss - усреднённая:\n",
    "   $$\n",
    "     \\mathcal{L}\n",
    "     = \\frac{1}{W}\\sum_{i,j} w_{ij}\\;\\ell_{ij}.\n",
    "   $$\n",
    "6. Если $W=0$ (нет ни одной пары с $t_i>t_j$), возвращаем нуль.\n",
    "\n",
    "Таким образом, CalibratedPairwiseLogistic минимизирует  \n",
    "$$\n",
    "-\\frac{1}{W}\\sum_{t_i>t_j}\\log\\frac{\\sigma(c_i)}{\\sigma(c_i)+\\sigma(c_j)},\n",
    "$$\n",
    "то есть учит давать более высокие оценки $c_i$ элементам с большим таргетом $t_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781b787f",
   "metadata": {},
   "source": [
    "Подсказка: используйте `make_pairs`, `log_softmax`, `logsigmoid`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4dc5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalibratedPairwiseLogistic(nn.Module):\n",
    "    def forward(self, logits, targets, lengths):\n",
    "        # TODO: your code here "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc63f57",
   "metadata": {},
   "source": [
    "В FinetuneModel к сырым логитам  \n",
    "$$\\ell_i = \\langle u_i, v_i\\rangle$$  \n",
    "применяется калибровка:\n",
    "\n",
    "1. Параметр «scale» (обозначим $s$) хранится в виде логарифма, то есть в модели он задан как $\\text{scale}$, а реальный множитель берётся как  \n",
    "   $$\n",
    "     \\alpha = \\exp(\\text{scale}).\n",
    "   $$\n",
    "\n",
    "2. Параметр «bias» (обозначим $b$) - это свободный смещающий коэффициент.\n",
    "\n",
    "Калиброванный логит получается по формуле  \n",
    "$$\n",
    "  \\hat\\ell_i \\;=\\; \\frac{\\ell_i}{\\alpha} \\;+\\; b\n",
    "  \\;=\\;\n",
    "  \\frac{\\langle u_i, v_i\\rangle}{\\exp(\\text{s})} \\;+\\; b.\n",
    "$$\n",
    "\n",
    "Благодаря этому механизмy модель может автоматически подстраивать и жёсткость (разброс) логитов (через $\\alpha$), и их среднее значение (через $b$), что важно для оптимальной работы попарной логистической функции потерь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b8ee30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinetuneModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                 backbone,\n",
    "                 embedding_dim=64):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.user_context_fusion = nn.Sequential(\n",
    "            ResNet(2 * embedding_dim),\n",
    "            ResNet(2 * embedding_dim),\n",
    "            ResNet(2 * embedding_dim),\n",
    "            nn.Linear(2 * embedding_dim, embedding_dim),\n",
    "        )\n",
    "        self.candidate_projector = nn.Sequential(\n",
    "            ResNet(embedding_dim),\n",
    "            ResNet(embedding_dim),\n",
    "            ResNet(embedding_dim),\n",
    "        )\n",
    "        self._embedding_dim = embedding_dim\n",
    "        self.scale = torch.nn.Parameter(torch.zeros(1, dtype=torch.float32))\n",
    "        self.bias = torch.nn.Parameter(torch.zeros(1, dtype=torch.float32))\n",
    "        self.pairwise_loss = CalibratedPairwiseLogistic()\n",
    "    \n",
    "    @property\n",
    "    def embedding_dim(self):\n",
    "        return self._embedding_dim\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        backbone_outputs = # TODO: your code here \n",
    "        source_embeddings = # TODO: your code here \n",
    "\n",
    "        lengths = # TODO: your code here \n",
    "        offsets = # TODO: your code here \n",
    "        target_inds = # TODO: your code here \n",
    "        source_embeddings = # TODO: your code here \n",
    "\n",
    "        source_embeddings = torch.nn.functional.normalize(# TODO: your code here)\n",
    "        candidate_embeddings = torch.nn.functional.normalize(# TODO: your code here )\n",
    "        source_embeddings = # TODO: your code here \n",
    "        output_logits = # TODO: your code here \n",
    "\n",
    "        return {\n",
    "            'logits': output_logits,\n",
    "            'loss': \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d6b63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_finetune_model():\n",
    "    sample = {\n",
    "        'history': {\n",
    "            'source_type': torch.tensor([8, 8, 8, 8, 8]), \n",
    "            'action_type': torch.tensor([1, 1, 2, 2, 1]), \n",
    "            'product_id': torch.tensor([ 3551, 17044, 10396, 10396, 10396]), \n",
    "            'position': torch.tensor([0, 1, 2, 3, 4]), 'targets_inds': torch.tensor([1]), \n",
    "            'targets_lengths': torch.tensor([1]), \n",
    "            'lengths': torch.tensor([5])\n",
    "        }, \n",
    "        'candidates': {\n",
    "            'source_type': torch.tensor([8]), \n",
    "            'action_type': torch.tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]), \n",
    "            'product_id': torch.tensor([18391,  6750, 21647,  5339,  3171,  6150,  3454, 20012, 19954, 10690, 24020,  5551,  5699, 17388, 10396]), \n",
    "        'lengths': torch.tensor([15]), \n",
    "        'num_requests': torch.tensor([1])\n",
    "        }\n",
    "    }\n",
    "    backbone = ModelBackbone()\n",
    "    model_finetune = FinetuneModel(backbone)\n",
    "    output = model_finetune(sample)\n",
    "    assert output['logits'].shape == (15,)\n",
    "    assert output['loss'].shape == ()\n",
    "\n",
    "test_finetune_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e01cb1",
   "metadata": {},
   "source": [
    "## 10. (0.5 балл) Обучаем finetune модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615e6b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_finetune_model(model, train_loader, valid_loader, optimizer, scheduler, num_epochs, device):\n",
    "    prev_valid_ndcg = None\n",
    "    global_cnt = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_losses = [] \n",
    "        for batch in tqdm(train_loader):\n",
    "            batch = move_to_device(batch, device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = model(batch)['loss']\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "        scheduler.step()\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {mean(train_losses):.6f}\")\n",
    "\n",
    "        model.eval()\n",
    "        valid_losses = []\n",
    "        valid_logits = [] \n",
    "        valid_targets = []\n",
    "        with torch.inference_mode():\n",
    "            for batch in tqdm(valid_loader):\n",
    "                batch = move_to_device(batch, device)\n",
    "                output = model(batch)\n",
    "                loss = output['loss']\n",
    "                valid_losses.append(loss.item())\n",
    "                logits = output['logits']\n",
    "                targets = batch['candidates']['action_type']\n",
    "                lengths = batch['candidates']['lengths']\n",
    "                i = 0\n",
    "                for length in lengths:\n",
    "                    if length > 1:\n",
    "                        valid_logits.append(logits[i:i + length].cpu().numpy())\n",
    "                        valid_targets.append(targets[i:i + length].cpu().numpy())\n",
    "                    i += length\n",
    "\n",
    "        avg_valid_ndcg = 0\n",
    "        for logits, targets in zip(valid_logits, valid_targets):\n",
    "            avg_valid_ndcg += ndcg_score(targets[None,], logits[None,], k=10, ignore_ties=True)\n",
    "        avg_valid_ndcg /= len(valid_logits)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Valid Loss: {mean(valid_losses):.6f}\")\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Valid NDCG@10: {avg_valid_ndcg}\")\n",
    "        \n",
    "        if prev_valid_ndcg is None or prev_valid_ndcg < avg_valid_ndcg:\n",
    "            global_cnt = 0\n",
    "            prev_valid_ndcg = avg_valid_ndcg\n",
    "            with torch.no_grad():\n",
    "                torch.save(model, './finetune.pt')\n",
    "        else:\n",
    "            global_cnt += 1\n",
    "            if global_cnt == 10:\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c2575f",
   "metadata": {},
   "source": [
    "Параметры и инициализации можно менять для пробития порогов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e451a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "batch_size = 4 \n",
    "warmup_epochs = 3\n",
    "start_factor = 0.1\n",
    "num_epochs = 100\n",
    "\n",
    "embedding_dim = 64\n",
    "num_heads = 2\n",
    "max_seq_len = 512\n",
    "dropout_rate = 0.1\n",
    "num_transformer_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48982863",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = # TODO: your code here \n",
    "valid_loader = # TODO: your code here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ca8060",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = # TODO: your code here \n",
    "model_finetune = # TODO: your code here \n",
    "optimizer = optim.AdamW(model_finetune.parameters(), lr=lr, weight_decay=0.01)\n",
    "scheduler = optim.lr_scheduler.LinearLR(\n",
    "    optimizer,\n",
    "    start_factor=start_factor,\n",
    "    total_iters=warmup_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269f6509",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_finetune_model(model_finetune, train_loader, valid_loader, optimizer, scheduler, num_epochs, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0229cdc8",
   "metadata": {},
   "source": [
    "Пробуем инициализироваться предобученной моделью, только backbone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a77b8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pretrain = torch.load('./pretrain.pt', weights_only=False)\n",
    "model_finetune = FinetuneModel(model_pretrain.backbone, embedding_dim).to(device)\n",
    "optimizer = optim.AdamW(model_finetune.parameters(), lr=lr, weight_decay=0.01)\n",
    "scheduler = optim.lr_scheduler.LinearLR(\n",
    "    optimizer,\n",
    "    start_factor=start_factor,\n",
    "    total_iters=warmup_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79b3af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_finetune_model(model_finetune, train_loader, valid_loader, optimizer, scheduler, num_epochs, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d7521a",
   "metadata": {},
   "source": [
    "Попробуем еще дополнительно иницилизировать user_context_fusion и candidate_projector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d2cf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pretrain = torch.load('./pretrain.pt', weights_only=False)\n",
    "model_finetune = FinetuneModel(model_pretrain.backbone, embedding_dim).to(device)\n",
    "model_finetune.user_context_fusion = model_pretrain.user_context_fusion\n",
    "model_finetune.candidate_projector = model_pretrain.candidate_projector\n",
    "\n",
    "optimizer = optim.AdamW(model_finetune.parameters(), lr=lr, weight_decay=0.01)\n",
    "scheduler = optim.lr_scheduler.LinearLR(\n",
    "    optimizer,\n",
    "    start_factor=start_factor,\n",
    "    total_iters=warmup_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9ae51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_finetune_model(model_finetune, train_loader, valid_loader, optimizer, scheduler, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58b7aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_finetune_model(valid_loader):\n",
    "    valid_logits = []\n",
    "    valid_targets = []\n",
    "    with torch.inference_mode():\n",
    "        test_model = torch.load('./finetune.pt', weights_only=False)\n",
    "        for batch in tqdm(valid_loader):\n",
    "            batch = move_to_device(batch, device)\n",
    "            output = test_model(batch)\n",
    "            logits = output['logits']\n",
    "            targets = batch['candidates']['action_type']\n",
    "            lengths = batch['candidates']['lengths']\n",
    "            i = 0\n",
    "            for length in lengths:\n",
    "                if length > 1:\n",
    "                    valid_logits.append(logits[i:i + length].cpu().numpy())\n",
    "                    valid_targets.append(targets[i:i + length].cpu().numpy())\n",
    "                i += length\n",
    "\n",
    "    avg_valid_ndcg = 0\n",
    "    for logits, targets in zip(valid_logits, valid_targets):\n",
    "        avg_valid_ndcg += ndcg_score(targets[None,], logits[None,], k=10, ignore_ties=True)\n",
    "    avg_valid_ndcg /= len(valid_logits)\n",
    "    assert avg_valid_ndcg > 0.324\n",
    "\n",
    "test_finetune_model(valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a078fc20",
   "metadata": {},
   "source": [
    "#### Вывод\n",
    "- Напишите вывод про влияние pretrain на качество решаемой задачи.\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd90bc75",
   "metadata": {},
   "source": [
    "## 11. Оцениваем качество в CatBoost и пробуем в контесте (этот пункт не оценивается)\n",
    "\n",
    "- Аналогично тому, как в домашнtv задании мы получали логиты для валидации, можно сгенерировать логиты и на тестовом наборе из контеста. После этого получившийся скаляр присоединяется к фичам CatBoost для трейна и теста:  \n",
    "    ```python\n",
    "    train_catboost = train_catboost.join(\n",
    "        argus_score,\n",
    "        on=['request_id', 'product_id'],\n",
    "        how='left'\n",
    "    )\n",
    "    valid_catboost = valid_catboost.join(\n",
    "        argus_score,\n",
    "        on=['request_id', 'product_id'],\n",
    "        how='left'\n",
    "    )\n",
    "    ```\n",
    "  Джойн выполняется по паре `(request_id, product_id)`. Чтобы это работало, в `Mapper`, `HistoryDeque` и `Candidates` нужно дополнительно передавать поле `request_id` в виде строки.\n",
    "\n",
    "- **Очень важно!** Периоды обучения трансформера и CatBoost не должны пересекаться. Иначе через этот признак «просочится» таргет, и CatBoost переобучится: вы увидите его на первой позиции по fstr, но реального улучшения в контесте не будет.\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"https://i.ibb.co/mVcH51gW/IMG000-18.jpg\" width=\"500\" alt=\"as_feature\">\n",
    "</div>\n",
    "\n",
    "- После джойна и обучения CatBoost признак окажется в числе первых по важности (fstr), вы получите прирост валидационных метрик и результатов на лидерборде Kaggle. Однако не стоит рассчитывать на космический эффект - обычно это +0.001…0.005, в зависимости от вышего набора признаков.\n",
    "\n",
    "- На практике такие алгоритмы работают гораздо эффективнее, поскольку для нейросетевых рекомендательных алгоритмов критично большое количество данных. В контесте же мы оперируем очень скромным объёмом, и методы не могут раскрыться полностью."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b664aa",
   "metadata": {},
   "source": [
    "## 12. (1 балл) Бонус 1: Расширение модели новыми признаками и текстовой модальностью\n",
    "\n",
    "- Нейросети выигрывают у градиентного бустинга благодаря способности принимать на вход данные разных типов и структур: тексты, графы, изображения, аудио и т. д. В этом бонусе предлагается дополнить модель двумя категориальными признаками (`city_name`, `store_id`), двумя текстовыми (`product_name`, `product_category`) и закодировать `timestamp`.\n",
    "- Для кодирования текстов используйте подход Bag of Words:  \n",
    "  1) Токенизируйте `product_name` и `product_category` с помощью модели [DmitryPogrebnoy/distilbert-base-russian-cased](DmitryPogrebnoy/distilbert-base-russian-cased).  \n",
    "  2) Получайте вектор признака как сумму эмбеддингов всех токенов.\n",
    "- Для кодирования времени отдельно заведите категориальный признак для часа дня (24 уникальных значения), для дня недели (7 уникальных значений), для месяца (12 уникальных значений). Можете рассмотреть и более продвинутые схемы (см. appendix [Actions Speak Louder than Words: Trillion-Parameter Sequential Transducers for Generative Recommendations](https://arxiv.org/abs/2402.17152)). \n",
    "- Для объединения (агрегации) всех признаков в единый вектор внедрите CrossLayer из семинара 5. Для этого расширьте `ItemEncoder`, добавив в него Cross-слой, связывающий категориальные и текстовые фичи.\n",
    "- Используйте одну и ту же матрицу эмбеддингов для текстовых признаков `product_name` и `product_category`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbd6157",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossLayer(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        # TODO: your code here\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6295b3e1",
   "metadata": {},
   "source": [
    "## 13. (1 балл) Бонус 2: Добавление в модель изображений\n",
    "\n",
    "- Аналогично расширьте модель визуальной информацией.\n",
    "- Учтите, что скачивание изображений может занять значительное время - до 8–10 часов.\n",
    "- Для кодирования изображений в вектор пользуйтесь любой предобученной моделью.\n",
    "- Пример скачивания картинок и сохранения их векторов:\n",
    "\n",
    "    ```python\n",
    "    import polars as pl\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    from io import BytesIO\n",
    "    import os\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torchvision.models as models\n",
    "    import torchvision.transforms as transforms\n",
    "    from tqdm import tqdm\n",
    "    import numpy as np\n",
    "\n",
    "    PARQUET_PATH = 'product2image.parquet'\n",
    "    EMBEDDING_SAVE_PATH = 'product_embeddings.pth'\n",
    "    MAX_PRODUCT_ID = 26_110\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    df = pl.read_parquet(PARQUET_PATH)\n",
    "\n",
    "    def download_and_process_image(url):\n",
    "        \"\"\"Downloads an image from URL, processes it, returns PIL Image or None on error.\"\"\"\n",
    "        try:\n",
    "            headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
    "            response = requests.get(url, timeout=15, headers=headers, stream=True)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            content_type = response.headers.get('Content-Type')\n",
    "            if content_type and not content_type.startswith('image/'):\n",
    "                print(f\"Warning: URL does not point to an image (Content-Type: {content_type}). Skipping.\")\n",
    "                return None\n",
    "\n",
    "            img = Image.open(BytesIO(response.content))\n",
    "            if img.mode != 'RGB':\n",
    "                img = img.convert('RGB')\n",
    "            return img\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Warning: Network error downloading image from {url}: {e}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Failed to process image from {url}: {e}\")\n",
    "            return None\n",
    "\n",
    "    model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "    model = nn.Sequential(*list(model.children())[:-1])\n",
    "    model.eval()\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    print(\"Extracting features from images...\")\n",
    "    product_vectors = {}\n",
    "    embedding_dim = None\n",
    "    processed_count = 0\n",
    "\n",
    "    for row in tqdm(df.iter_rows(named=True), total=len(df), desc=\"Processing images\"):\n",
    "        product_id = row['product_id']\n",
    "        url = row['product_image']\n",
    "\n",
    "        if not (url and isinstance(url, str) and url.startswith('http')):\n",
    "            print(f\"Warning: Invalid URL for product_id {product_id}: {url}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        img = download_and_process_image(url)\n",
    "\n",
    "        if img is None:\n",
    "            # The warning is printed inside download_and_process_image\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            img_t = preprocess(img)\n",
    "            batch_t = torch.unsqueeze(img_t, 0).to(DEVICE)\n",
    "\n",
    "            with torch.inference_mode():\n",
    "                features = model(batch_t)\n",
    "\n",
    "            vector = features.squeeze().cpu().numpy()\n",
    "            product_vectors[product_id] = vector\n",
    "            processed_count += 1\n",
    "\n",
    "            if embedding_dim is None:\n",
    "                embedding_dim = vector.shape[0]\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Failed to generate vector for product_id {product_id} from URL {url}: {e}\")\n",
    "        \n",
    "    print(f\"Image processing complete. Successfully generated vectors for {processed_count} images.\")\n",
    "\n",
    "    if not product_vectors:\n",
    "        print(\"Error: No features were extracted from any image. Check warning logs. Exiting.\")\n",
    "        exit()\n",
    "\n",
    "    if embedding_dim is None:\n",
    "        print(\"Error: Embedding dimension could not be determined (no images processed successfully). Exiting.\")\n",
    "        exit()\n",
    "\n",
    "    num_embeddings = MAX_PRODUCT_ID + 1\n",
    "    embedding_layer = nn.Embedding(num_embeddings=num_embeddings, embedding_dim=embedding_dim, padding_idx=None)\n",
    "\n",
    "    embedding_layer.weight.data.zero_()\n",
    "\n",
    "    vectors_loaded = 0\n",
    "    for product_id, vector in product_vectors.items():\n",
    "        if isinstance(product_id, (int, np.integer)) and 0 <= product_id < num_embeddings:\n",
    "            embedding_layer.weight.data[product_id] = torch.tensor(vector)\n",
    "            vectors_loaded += 1\n",
    "        else:\n",
    "            print(f\"Warning: Product ID {product_id} (type: {type(product_id)}) is invalid or out of range [0, {MAX_PRODUCT_ID}]. Skipping vector assignment.\")\n",
    "\n",
    "    print(f\"nn.Embedding layer weights initialized with {vectors_loaded} vectors.\")\n",
    "\n",
    "    torch.save(embedding_layer.state_dict(), EMBEDDING_SAVE_PATH)\n",
    "    print(f\"Embedding layer state_dict saved to file: '{EMBEDDING_SAVE_PATH}'\")\n",
    "    ```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yrec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
